{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random Tweets\n",
    "\n",
    "This notebook uses Markov Chains models in order to generate random texts (with a maximum length equal to a Tweet).\n",
    "\n",
    "Although it can generate reasonably accurate results, it's a completely synthetic dataset! Because of this, instead of using the generated data as training data for our NER model, we simply use it to study which text operation can improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Markov Chains model\n",
    "\n",
    "Here we simply provide a series of raw text files in order to create our model - which we then save as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import glob\n",
    "\n",
    "max_tweet_size = 140\n",
    "raw_text_files_path = 'data/raw/markov_text_files/*.txt'\n",
    "parsed_model_file_path = 'data/parsed/markov_text_files/markov_weighted_chain.json'\n",
    "raw_text_file_paths = glob.glob(raw_text_files_path)\n",
    "raw_text_markov_models = []\n",
    "\n",
    "# Read raw text files and generate Markov chain models\n",
    "for file_path in raw_text_file_paths:\n",
    "    with open(file_path) as file:\n",
    "        text = file.read()\n",
    "        markov_model = markovify.Text(text, state_size=4)\n",
    "        raw_text_markov_models.append(markov_model)\n",
    "    \n",
    "# Combine all generated models into a single one\n",
    "markov_model = markovify.combine(raw_text_markov_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_In deeply seated bones_, such as the upper end of the humerus, may be the seat of excruciating pain.\n",
      "I had no idea that he was in fear of someone or something which drove him from America.\n",
      "He swore on his honor that the Russians were running away and that he himself was formulating.\n",
      "Quinine, in 5 to 10 grain doses every four hours, have also been employed with apparent benefit.\n",
      "He looked about him anxiously in the glare of the streets could at first see nothing.\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 random sentences from the generated Markov chain model\n",
    "for i in range(5):\n",
    "    print(markov_model.make_short_sentence(max_tweet_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model as JSON\n",
    "model_json = markov_model.chain.to_json()\n",
    "with open(parsed_model_file_path, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improving the model\n",
    "\n",
    "Even though we want to generate completely random Tweet-like texts, our aim is to improve the accuracy of our NER model for Country/Nationality/Religion/Currency recognition. Having said that, we will go through our model, generate a set amount of samples and use them as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define target datasets' paths\n",
    "parsed_country_nationality_file = 'data/parsed/parsed_country_nationality.csv'\n",
    "parsed_currency_country_file = 'data/parsed/parsed_currency_country.csv'\n",
    "parsed_country_religion_file = 'data/parsed/country_religion_files/parsed_country_religion.csv'\n",
    "parsed_country_cities_file = 'data/parsed/parsed_country_cities.csv'\n",
    "\n",
    "# Load the necessary datasets\n",
    "country_nationality_df = pd.read_csv(parsed_country_nationality_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "currency_country_df = pd.read_csv(parsed_currency_country_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "country_religion_df = pd.read_csv(parsed_country_religion_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "country_cities_df = pd.read_csv(parsed_country_cities_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "\n",
    "# Store unique sets\n",
    "unique_country_common_names = country_nationality_df['Common Name'].astype(str).unique()\n",
    "unique_country_official_names = country_nationality_df['Official Name'].astype(str).unique()\n",
    "unique_country_nationalities = country_nationality_df['Nationality'].astype(str).unique()\n",
    "unique_country_religions_name = country_religion_df['Religion'].astype(str).unique()\n",
    "unique_country_rilogions_affiliation = country_religion_df['Affiliation'].astype(str).unique()\n",
    "unique_currency_ids = currency_country_df['ID'].astype(str).unique()\n",
    "unique_country_city_names = country_cities_df['City'].astype(str).unique()\n",
    "# TODO also add currencies' full names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# Define important word sets\n",
    "important_word_sets = [\n",
    "    list(map(lambda x : x.upper(), unique_country_common_names)),\n",
    "    list(map(lambda x : x.upper(), unique_country_official_names)),\n",
    "    list(map(lambda x : x.upper(), unique_country_nationalities)),\n",
    "    list(map(lambda x : x.upper(), unique_country_religions_name)),\n",
    "    list(map(lambda x : x.upper(), unique_country_rilogions_affiliation)),\n",
    "    list(map(lambda x : x.upper(), unique_currency_ids)),\n",
    "    list(map(lambda x : x.upper(), unique_country_city_names))\n",
    "]\n",
    "\n",
    "def is_word_important(word):\n",
    "    '''\n",
    "    This method checks wether or not a word\n",
    "    is considered to be 'important'.\n",
    "    '''\n",
    "    # Set regex for word parsing\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    \n",
    "    for important_word_set in important_word_sets:\n",
    "        comparable_word = regex.sub('', word).upper()\n",
    "        if comparable_word in important_word_set:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_testing_samples_dict(max_testing_samples, unnecessary_sample_retention_percent):\n",
    "    # Define number of sentences to generate\n",
    "    cur_testing_samples = 0\n",
    "\n",
    "    testing_sample_dict = {}\n",
    "    while len(testing_sample_dict.keys()) < max_testing_samples:\n",
    "        batch_size = max_testing_samples - cur_testing_samples\n",
    "        samples = [markov_model.make_short_sentence(max_tweet_size) for i in range(batch_size)]\n",
    "        \n",
    "        for sample in samples:\n",
    "            contains_important_word = False\n",
    "            if sample is None:\n",
    "                continue\n",
    "            for word in sample.split():\n",
    "                if is_word_important(word):\n",
    "                    contains_important_word = True\n",
    "                    break\n",
    "            if (contains_important_word):\n",
    "                print('\\n[New Sample]\\nText: {}'.format(sample))\n",
    "                n_city_names = int(input('[1/6] # City Names: '))\n",
    "                n_country_names = int(input('[2/6] # Country Names: '))\n",
    "                n_country_nationalities = int(input('[3/6] # Nationalities: '))\n",
    "                n_religion_names = int(input('[4/6] # Religion names: '))\n",
    "                n_religion_affiliations = int(input('[5/6] # Religious affiliations: '))\n",
    "                n_currency_names = int(input('[6/6] # Currency names: '))\n",
    "                \n",
    "                n_param_sum = n_city_names + n_country_names + n_country_nationalities + n_religion_names + n_religion_affiliations + n_currency_names\n",
    "                if (n_param_sum > 0 or random.randint(0,100) <= unnecessary_sample_retention_percent):\n",
    "                    testing_sample_dict[cur_testing_samples] = {\n",
    "                        'Text': sample,\n",
    "                        'City Names': n_city_names,\n",
    "                        'Country Names': n_country_names,\n",
    "                        'Country Nationalities': n_country_nationalities,\n",
    "                        'Religion Names': n_religion_names,\n",
    "                        'Religion Affiliations': n_religion_affiliations,\n",
    "                        'Currency Names': n_currency_names\n",
    "                    }\n",
    "                    cur_testing_samples += 1\n",
    "                    print('[{}/{} SAVED]'.format(cur_testing_samples, max_testing_samples))\n",
    "                else:\n",
    "                    print('[DISCARDED]')\n",
    "    return testing_sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[New Sample]\n",
      "Text: Pacific Ocean The Pacific Ocean is a major contributor to the world economy has made manufacturing in China much more cost effective.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: They all appear to be adhesive, and there is a remarkable absence of pain.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: Having cleared the way Denisov stopped at the end of the Cold War allowed for German unification in 1990.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: The ejaculation had been drawn from my companion by the fact that there was nothing left to do as a Russian.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: What more could she write after all that had happened to him, but he passed away without having ever recovered his consciousness.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: He saw on the one hand the French had occupied Moscow.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: Ecuador What is now Ecuador formed part of the daily diet of the household.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: Ring-pads of wool, air-cushions, or water-bags, and must be kept absolutely quiet and free from all sources of irritation.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: When he read that sentence, Pierre felt for the first time all the cruelty of his rupture with her.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: Jamaica gained full independence when it withdrew from the protectorate and joined the Commonwealth of Nations in 1981.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: Slovakia The dissolution of the Netherlands Antilles.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[DISCARDED]\n",
      "\n",
      "[New Sample]\n",
      "Text: Moldova's dependence on Russian energy was underscored at the end of a fortnight or three weeks improvement may begin.\n",
      "[1/5] # Country Names: 1\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 1\n",
      "[4/5] # Religious affiliations: 1\n",
      "[5/5] # Currency names: 1\n",
      "[1/2 SAVED]\n",
      "\n",
      "[New Sample]\n",
      "Text: China generally has implemented reforms in a gradualist or piecemeal fashion.\n",
      "[1/5] # Country Names: 0\n",
      "[2/5] # Nationalities: 0\n",
      "[3/5] # Religion names: 0\n",
      "[4/5] # Religious affiliations: 0\n",
      "[5/5] # Currency names: 0\n",
      "[2/2 SAVED]\n"
     ]
    }
   ],
   "source": [
    "sample_dict = generate_testing_samples_dict(2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Country Names</th>\n",
       "      <th>Country Nationalities</th>\n",
       "      <th>Religion Names</th>\n",
       "      <th>Religion Affiliations</th>\n",
       "      <th>Currency Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moldova's dependence on Russian energy was und...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China generally has implemented reforms in a g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Country Names  \\\n",
       "0  Moldova's dependence on Russian energy was und...              1   \n",
       "1  China generally has implemented reforms in a g...              0   \n",
       "\n",
       "   Country Nationalities  Religion Names  Religion Affiliations  \\\n",
       "0                      0               1                      1   \n",
       "1                      0               0                      0   \n",
       "\n",
       "   Currency Names  \n",
       "0               1  \n",
       "1               0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.DataFrame.from_dict(sample_dict, orient='index')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
