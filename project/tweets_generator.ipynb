{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random Tweets\n",
    "\n",
    "This notebook uses Markov Chains models in order to generate random texts (with a maximum length equal to a Tweet).\n",
    "\n",
    "Although it can generate reasonably accurate results, it's a completely synthetic dataset! Because of this, instead of using the generated data as training data for our NER model, we simply use it to study which text operation can improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Markov Chains model\n",
    "\n",
    "Here we simply provide a series of raw text files in order to create our model - which we then save as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import glob\n",
    "\n",
    "max_tweet_size = 140\n",
    "raw_text_files_path = 'data/raw/markov_text_files/*.txt'\n",
    "parsed_model_file_path = 'data/parsed/markov_text_files/markov_weighted_chain.json'\n",
    "raw_text_file_paths = glob.glob(raw_text_files_path)\n",
    "raw_text_markov_models = []\n",
    "\n",
    "# Read raw text files and generate Markov chain models\n",
    "for file_path in raw_text_file_paths:\n",
    "    with open(file_path) as file:\n",
    "        text = file.read()\n",
    "        markov_model = markovify.Text(text)\n",
    "        raw_text_markov_models.append(markov_model)\n",
    "    \n",
    "# Combine all generated models into a single one\n",
    "markov_model = markovify.combine(raw_text_markov_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A third, in the groin.\n",
      "Princess Mary pass into the House of Lords was composed of sodium and potassium.\n"
     ]
    }
   ],
   "source": [
    "# Generate 10 random sentences from the generated Markov chain model\n",
    "for i in range(2):\n",
    "    print(markov_model.make_short_sentence(max_tweet_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model as JSON\n",
    "model_json = markov_model.chain.to_json()\n",
    "with open(parsed_model_file_path, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improving the model\n",
    "\n",
    "Even though we want to generate completely random Tweet-like texts, our aim is to improve the accuracy of our NER model for Country/Nationality/Religion/Currency recognition. Having said that, we will go through our model and increase the weight of words that we know represent one of these things.\n",
    "\n",
    "By increasing their weight, we will simply make it mode likely that these words will popup in the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the necessary datasets\n",
    "country_nationality_df = pd.read_csv('data/parsed/parsed_country_nationality.csv', encoding='utf-8', compression='gzip', index_col=False)\n",
    "currency_country_df = pd.read_csv('data/parsed/parsed_currency_country.csv', encoding='utf-8', compression='gzip', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
