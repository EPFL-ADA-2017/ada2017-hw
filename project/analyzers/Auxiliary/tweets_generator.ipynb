{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random Tweets\n",
    "\n",
    "This notebook uses Markov Chains models in order to generate random texts (with a maximum length equal to a Tweet).\n",
    "\n",
    "Although it can generate reasonably accurate results, it's a completely synthetic dataset! Because of this, instead of using the generated data as training data for our NER model, we simply use it to study which text operation can improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Markov Chains model\n",
    "\n",
    "Here we simply provide a series of raw text files in order to create our model - which we then save as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import glob\n",
    "\n",
    "max_tweet_size = 140\n",
    "raw_text_files_path = '../../data/raw/markov_text_files/*.txt'\n",
    "parsed_model_file_path = '../../data/parsed/markov_text_files/markov_weighted_chain.json'\n",
    "raw_text_file_paths = glob.glob(raw_text_files_path)\n",
    "raw_text_markov_models = []\n",
    "\n",
    "# Read raw text files and generate Markov chain models\n",
    "weights = []\n",
    "for file_path in raw_text_file_paths:\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        markov_model = markovify.Text(text, state_size=4)\n",
    "        raw_text_markov_models.append(markov_model)\n",
    "        if 'religion' in file_path:\n",
    "            weights.append(2)\n",
    "        else:\n",
    "            weights.append(1)\n",
    "    \n",
    "# Combine all generated models into a single one\n",
    "markov_model = markovify.combine(raw_text_markov_models, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dolokhov who was in the same yard as themselves and in a part of the law of that state.\n",
      "Boris, too, with his friend Zhilinski, came to see the prince about twice a week.\n",
      "On account of the liability to lesions of the mouth also contains the organism.\n",
      "The mother smoothed the folds of her velvet dress picturesquely.\n",
      "When the convention assembled in 1786, it was found that he had left it there.\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 random sentences from the generated Markov chain model\n",
    "for i in range(5):\n",
    "    print(markov_model.make_short_sentence(max_tweet_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model as JSON\n",
    "model_json = markov_model.chain.to_json()\n",
    "with open(parsed_model_file_path, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improving the model\n",
    "\n",
    "Even though we want to generate completely random Tweet-like texts, our aim is to improve the accuracy of our NER model for Country/Nationality/Religion/Currency recognition. Having said that, we will go through our model, generate a set amount of samples and use them as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define target datasets' paths\n",
    "parsed_country_nationality_file = '../../data/parsed/parsed_country_nationality.csv'\n",
    "parsed_currency_country_file = '../../data/parsed/parsed_currency_country.csv'\n",
    "parsed_country_religion_file = '../../data/parsed/country_religion_files/parsed_country_religion.csv'\n",
    "parsed_country_cities_file = '../../data/parsed/parsed_country_cities.csv'\n",
    "\n",
    "# Load the necessary datasets\n",
    "country_nationality_df = pd.read_csv(parsed_country_nationality_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "currency_country_df = pd.read_csv(parsed_currency_country_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "country_religion_df = pd.read_csv(parsed_country_religion_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "country_cities_df = pd.read_csv(parsed_country_cities_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "\n",
    "# Store unique sets\n",
    "unique_country_common_names = country_nationality_df['Common Name'].astype(str).unique()\n",
    "unique_country_official_names = country_nationality_df['Official Name'].astype(str).unique()\n",
    "unique_country_nationalities = country_nationality_df['Nationality'].astype(str).unique()\n",
    "unique_country_religions_name = country_religion_df['Religion'].astype(str).unique()\n",
    "unique_country_rilogions_affiliation = country_religion_df['Affiliation'].astype(str).unique()\n",
    "unique_currency_ids = currency_country_df['ID'].astype(str).unique()\n",
    "unique_country_city_names = country_cities_df['City'].astype(str).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# Define important word sets\n",
    "important_word_dict = {\n",
    "    'Country Names': list(map(lambda x : x.upper(), unique_country_common_names)),\n",
    "    'Country Names (Official)': list(map(lambda x : x.upper(), unique_country_official_names)),\n",
    "    'Country Nationalities': list(map(lambda x : x.upper(), unique_country_nationalities)),\n",
    "    'Religion Names': list(map(lambda x : x.upper(), unique_country_religions_name)),\n",
    "    'Religion Affiliations': list(map(lambda x : x.upper(), unique_country_rilogions_affiliation)),\n",
    "    'Currencies': list(map(lambda x : x.upper(), unique_currency_ids)),\n",
    "    'City Names': list(map(lambda x : x.upper(), unique_country_city_names))\n",
    "}\n",
    "\n",
    "def get_word_label(word):\n",
    "    '''\n",
    "    This method checks wether or not a word\n",
    "    is considered to be 'important'.\n",
    "    '''\n",
    "    # Set regex for word parsing\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    \n",
    "    for important_word_label, important_word_set in important_word_dict.items():\n",
    "        comparable_word = regex.sub('', word).upper()\n",
    "        if comparable_word in important_word_set:\n",
    "            return important_word_label\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_int_input(string):\n",
    "    try:\n",
    "        return int(input(string))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_testing_samples_dict(max_testing_samples, unnecessary_sample_retention_percent):\n",
    "    # Define number of sentences to generate\n",
    "    cur_testing_samples = 0\n",
    "\n",
    "    testing_sample_dict = {}\n",
    "    while len(testing_sample_dict.keys()) < max_testing_samples:\n",
    "        batch_size = max_testing_samples - cur_testing_samples\n",
    "        samples = [markov_model.make_short_sentence(max_tweet_size) for i in range(batch_size)]\n",
    "        \n",
    "        for sample in samples:\n",
    "            important_words_dict = {}\n",
    "            contains_important_word = False\n",
    "            if sample is None:\n",
    "                continue\n",
    "            for word in sample.split():\n",
    "                word_label = get_word_label(word)\n",
    "                if word_label is not None:\n",
    "                    important_words_dict[word_label] = important_words_dict.get(word_label, list()) + [word]\n",
    "                    contains_important_word = True\n",
    "            if (contains_important_word):\n",
    "                print('------------------')\n",
    "                print('\\n| [New Sample]')\n",
    "                print('| \\tText: {}'.format(sample))\n",
    "                print('| [Analysis results]')\n",
    "                for label, word_list in important_words_dict.items():\n",
    "                    print('| \\t{}: {}'.format(label, word_list))\n",
    "                print('| [Verification]')\n",
    "                n_city_names = get_int_input('| \\t[1/6] # City Names: ')\n",
    "                n_country_names = get_int_input('| \\t[2/6] # Country Names: ')\n",
    "                n_country_nationalities = get_int_input('| \\t[3/6] # Nationalities: ')\n",
    "                n_religion_names = get_int_input('| \\t[4/6] # Religion names: ')\n",
    "                n_religion_affiliations = get_int_input('| \\t[5/6] # Religious affiliations: ')\n",
    "                n_currency_names = get_int_input('| \\t[6/6] # Currency names: ')\n",
    "                \n",
    "                n_param_sum = n_city_names + n_country_names + n_country_nationalities + n_religion_names + n_religion_affiliations + n_currency_names\n",
    "                if (n_param_sum > 0 or random.randint(0,100) <= unnecessary_sample_retention_percent):\n",
    "                    testing_sample_dict[cur_testing_samples] = {\n",
    "                        'Text': sample,\n",
    "                        'City Names': n_city_names,\n",
    "                        'Country Names': n_country_names,\n",
    "                        'Country Nationalities': n_country_nationalities,\n",
    "                        'Religion Names': n_religion_names,\n",
    "                        'Religion Affiliations': n_religion_affiliations,\n",
    "                        'Currency Names': n_currency_names\n",
    "                    }\n",
    "                    cur_testing_samples += 1\n",
    "                    print('[Result]')\n",
    "                    print('\\tSAVED ({}/{})'.format(cur_testing_samples, max_testing_samples))\n",
    "                else:\n",
    "                    print('[Result]')\n",
    "                    print('\\tDISCARDED')\n",
    "    return testing_sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_auto_religion_testing_samples_dict(max_testing_samples):\n",
    "    # Define number of sentences to generate\n",
    "    cur_testing_samples = 0\n",
    "\n",
    "    testing_sample_dict = {}\n",
    "    while len(testing_sample_dict.keys()) < max_testing_samples:\n",
    "        batch_size = max_testing_samples - cur_testing_samples\n",
    "        samples = [markov_model.make_short_sentence(max_tweet_size) for i in range(batch_size)]\n",
    "        \n",
    "        for sample in samples:\n",
    "            important_words_dict = {}\n",
    "            contains_important_word = False\n",
    "            if sample is None:\n",
    "                continue\n",
    "            for word in sample.split():\n",
    "                word_label = get_word_label(word)\n",
    "                if word_label in ['Religion Names', 'Religion Affiliations']:\n",
    "                    important_words_dict[word_label] = important_words_dict.get(word_label, list()) + [word]\n",
    "                    contains_important_word = True\n",
    "            if (contains_important_word):\n",
    "                print('\\n---Sample----------')\n",
    "                print('| [Text]')\n",
    "                print('| \\t{}'.format(sample))\n",
    "                print('| [Analysis results]')\n",
    "                for label, word_list in important_words_dict.items():\n",
    "                    print('| \\t{}: {}'.format(label, word_list))\n",
    "                print('| [Verification]')\n",
    "                \n",
    "                n_religion_names = len(important_words_dict.get('Religion Names', list()))\n",
    "                n_religion_affiliations = len(important_words_dict.get('Religion Affiliations', list()))\n",
    "                n_param_sum = len(important_words_dict)\n",
    "                if (n_param_sum > 0):\n",
    "                    testing_sample_dict[cur_testing_samples] = {\n",
    "                        'Text': sample,\n",
    "                        'City Names': 0,\n",
    "                        'Country Names': 0,\n",
    "                        'Country Nationalities': 0,\n",
    "                        'Religion Names': n_religion_names,\n",
    "                        'Religion Affiliations': n_religion_affiliations,\n",
    "                        'Currency Names': 0\n",
    "                    }\n",
    "                    cur_testing_samples += 1\n",
    "                    print('| [Result]')\n",
    "                    print('| \\tSAVED ({}/{})'.format(cur_testing_samples, max_testing_samples))\n",
    "                else:\n",
    "                    print('| [Result]')\n",
    "                    print('| \\tDISCARDED')\n",
    "                print('------------------')\n",
    "    return testing_sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tMany Orthodox Jewish communities believe that they will be described in their proper places.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Jewish']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (1/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tAll this was in addition to the Tanakh, also include the Deuterocanonical Books as part of the Jewish community at all, although most do.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Jewish']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (2/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tChristianity is one of the poorest countries in the world, with 65% of its land area is desert or semidesert.\n",
      "| [Analysis results]\n",
      "| \tReligion Names: ['Christianity']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (3/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tUnder the Geneva Accords of 1954, Vietnam was divided into the secular state of India and the smaller Muslim state of Pakistan.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Muslim']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (4/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tUnder the Geneva Accords of 1954, Vietnam was divided into the secular state of India and the smaller Muslim state of Pakistan.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Muslim']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (5/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tA Sunni Muslim may elect to follow any one of these positions because Kutuzov did not wish to do anything like that yet.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Muslim']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (6/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tUnder the Geneva Accords of 1954, Vietnam was divided into the secular state of India and the smaller Muslim state of Pakistan.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Muslim']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (7/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tNorthern Mariana Islands Under US administration as part of the Jewish community at all, although most do.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Jewish']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (8/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tUnder the Geneva Accords of 1954, Vietnam was divided into the secular state of India and the smaller Muslim state of Pakistan.\n",
      "| [Analysis results]\n",
      "| \tReligion Affiliations: ['Muslim']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (9/10)\n",
      "------------------\n",
      "\n",
      "---Sample----------\n",
      "| [Text]\n",
      "| \tKaraite Judaism defines itself as the remnants of the force which had suffered defeat in the south-west.\n",
      "| [Analysis results]\n",
      "| \tReligion Names: ['Judaism']\n",
      "| [Verification]\n",
      "| [Result]\n",
      "| \tSAVED (10/10)\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "sample_dict = generate_auto_religion_testing_samples_dict(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "sample_dict = generate_testing_samples_dict(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>City Names</th>\n",
       "      <th>Country Names</th>\n",
       "      <th>Country Nationalities</th>\n",
       "      <th>Religion Names</th>\n",
       "      <th>Religion Affiliations</th>\n",
       "      <th>Currency Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Many Orthodox Jewish communities believe that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All this was in addition to the Tanakh, also i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christianity is one of the poorest countries i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Under the Geneva Accords of 1954, Vietnam was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under the Geneva Accords of 1954, Vietnam was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  City Names  \\\n",
       "0  Many Orthodox Jewish communities believe that ...           0   \n",
       "1  All this was in addition to the Tanakh, also i...           0   \n",
       "2  Christianity is one of the poorest countries i...           0   \n",
       "3  Under the Geneva Accords of 1954, Vietnam was ...           0   \n",
       "4  Under the Geneva Accords of 1954, Vietnam was ...           0   \n",
       "\n",
       "   Country Names  Country Nationalities  Religion Names  \\\n",
       "0              0                      0               0   \n",
       "1              0                      0               0   \n",
       "2              0                      0               1   \n",
       "3              0                      0               0   \n",
       "4              0                      0               0   \n",
       "\n",
       "   Religion Affiliations  Currency Names  \n",
       "0                      1               0  \n",
       "1                      1               0  \n",
       "2                      0               0  \n",
       "3                      1               0  \n",
       "4                      1               0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.DataFrame.from_dict(sample_dict, orient='index')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define file path for output\n",
    "test_samples_file = '../../data/parsed/markov_text_files/test_samples_religion_4.csv'\n",
    "\n",
    "sample_df.to_csv(test_samples_file, encoding='utf-8', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_full_dataframe(generic=True, religion=True):\n",
    "    \n",
    "    full_sample_df = pd.DataFrame()\n",
    "    \n",
    "    if generic:\n",
    "        # Append generic samples\n",
    "        all_files = glob.glob('../../data/parsed/markov_text_files/test_samples_generic_*.csv')\n",
    "        for file in all_files:\n",
    "            temp_df = pd.read_csv(file, encoding='utf-8', compression='gzip')\n",
    "            full_sample_df = full_sample_df.append(temp_df)\n",
    "    \n",
    "    if religion:\n",
    "        # Append auto religion samples\n",
    "        all_files = glob.glob('../../data/parsed/markov_text_files/test_samples_religion_*.csv')\n",
    "        for file in all_files:\n",
    "            temp_df = pd.read_csv(file, encoding='utf-8', compression='gzip')\n",
    "            full_sample_df = full_sample_df.append(temp_df)\n",
    "    \n",
    "    print('Results obtained on {} tweets'.format(len(full_sample_df)))\n",
    "    \n",
    "    return full_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results obtained on 150 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City Names</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Names</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Nationalities</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion Names</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion Affiliations</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Currency Names</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Number of values\n",
       "City Names                          18\n",
       "Country Names                       83\n",
       "Country Nationalities               41\n",
       "Religion Names                       1\n",
       "Religion Affiliations                2\n",
       "Currency Names                       3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a global dataframe for all the samples\n",
    "full_sample_df = build_full_dataframe(religion=False)\n",
    "    \n",
    "# Verify the amount of values in total we have obtained for each category\n",
    "sum_sample_df = pd.DataFrame(full_sample_df.sum(axis=0))\n",
    "sum_sample_df.drop('Text', inplace=True)\n",
    "sum_sample_df.rename(columns={0:'Number of values'}, inplace=True)\n",
    "\n",
    "sum_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
