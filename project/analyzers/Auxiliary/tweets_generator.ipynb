{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random Tweets\n",
    "\n",
    "This notebook uses Markov Chains models in order to generate random texts (with a maximum length equal to a Tweet).\n",
    "\n",
    "Although it can generate reasonably accurate results, it's a completely synthetic dataset! Because of this, instead of using the generated data as training data for our NER model, we simply use it to study which text operation can improve its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Markov Chains model\n",
    "\n",
    "Here we simply provide a series of raw text files in order to create our model - which we then save as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import glob\n",
    "\n",
    "max_tweet_size = 140\n",
    "raw_text_files_path = 'data/raw/markov_text_files/*.txt'\n",
    "parsed_model_file_path = 'data/parsed/markov_text_files/markov_weighted_chain.json'\n",
    "raw_text_file_paths = glob.glob(raw_text_files_path)\n",
    "raw_text_markov_models = []\n",
    "\n",
    "# Read raw text files and generate Markov chain models\n",
    "weights = []\n",
    "for file_path in raw_text_file_paths:\n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        markov_model = markovify.Text(text, state_size=4)\n",
    "        raw_text_markov_models.append(markov_model)\n",
    "        if 'religion' in file_path:\n",
    "            weights.append(2)\n",
    "        else:\n",
    "            weights.append(1)\n",
    "    \n",
    "# Combine all generated models into a single one\n",
    "markov_model = markovify.combine(raw_text_markov_models, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donations are accepted in a number of continental European countries.\n",
      "Pierre heard it plainly, but at that moment fearful screams reached them from the avenue.\n",
      "When Marya Dmitrievna told Natasha that Anatole was married, with some arsenic she had stealthily procured.\n",
      "He had now been for some days in Moscow and was being taken along with him, having been wounded in the head and neck and in the extremities.\n",
      "Rank country Debt - external Date of Information 1 United States $ 2,581,000,000,000 31 December 2010 est.\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 random sentences from the generated Markov chain model\n",
    "for i in range(5):\n",
    "    print(markov_model.make_short_sentence(max_tweet_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model as JSON\n",
    "model_json = markov_model.chain.to_json()\n",
    "with open(parsed_model_file_path, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improving the model\n",
    "\n",
    "Even though we want to generate completely random Tweet-like texts, our aim is to improve the accuracy of our NER model for Country/Nationality/Religion/Currency recognition. Having said that, we will go through our model, generate a set amount of samples and use them as testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define target datasets' paths\n",
    "parsed_country_nationality_file = 'data/parsed/parsed_country_nationality.csv'\n",
    "parsed_currency_country_file = 'data/parsed/parsed_currency_country.csv'\n",
    "parsed_country_religion_file = 'data/parsed/country_religion_files/parsed_country_religion.csv'\n",
    "parsed_country_cities_file = 'data/parsed/parsed_country_cities.csv'\n",
    "\n",
    "# Load the necessary datasets\n",
    "country_nationality_df = pd.read_csv(parsed_country_nationality_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "currency_country_df = pd.read_csv(parsed_currency_country_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "country_religion_df = pd.read_csv(parsed_country_religion_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "country_cities_df = pd.read_csv(parsed_country_cities_file, encoding='utf-8', compression='gzip', index_col=False)\n",
    "\n",
    "# Store unique sets\n",
    "unique_country_common_names = country_nationality_df['Common Name'].astype(str).unique()\n",
    "unique_country_official_names = country_nationality_df['Official Name'].astype(str).unique()\n",
    "unique_country_nationalities = country_nationality_df['Nationality'].astype(str).unique()\n",
    "unique_country_religions_name = country_religion_df['Religion'].astype(str).unique()\n",
    "unique_country_rilogions_affiliation = country_religion_df['Affiliation'].astype(str).unique()\n",
    "unique_currency_ids = currency_country_df['ID'].astype(str).unique()\n",
    "unique_country_city_names = country_cities_df['City'].astype(str).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "# Define important word sets\n",
    "important_word_dict = {\n",
    "    'Country Names': list(map(lambda x : x.upper(), unique_country_common_names)),\n",
    "    'Country Names (Official)': list(map(lambda x : x.upper(), unique_country_official_names)),\n",
    "    'Country Nationalities': list(map(lambda x : x.upper(), unique_country_nationalities)),\n",
    "    'Religion Names': list(map(lambda x : x.upper(), unique_country_religions_name)),\n",
    "    'Religion Affiliations': list(map(lambda x : x.upper(), unique_country_rilogions_affiliation)),\n",
    "    'Currencies': list(map(lambda x : x.upper(), unique_currency_ids)),\n",
    "    'City Names': list(map(lambda x : x.upper(), unique_country_city_names))\n",
    "}\n",
    "\n",
    "def get_word_label(word):\n",
    "    '''\n",
    "    This method checks wether or not a word\n",
    "    is considered to be 'important'.\n",
    "    '''\n",
    "    # Set regex for word parsing\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    \n",
    "    for important_word_label, important_word_set in important_word_dict.items():\n",
    "        comparable_word = regex.sub('', word).upper()\n",
    "        if comparable_word in important_word_set:\n",
    "            return important_word_label\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_int_input(string):\n",
    "    try:\n",
    "        return int(input(string))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_testing_samples_dict(max_testing_samples, unnecessary_sample_retention_percent):\n",
    "    # Define number of sentences to generate\n",
    "    cur_testing_samples = 0\n",
    "\n",
    "    testing_sample_dict = {}\n",
    "    while len(testing_sample_dict.keys()) < max_testing_samples:\n",
    "        batch_size = max_testing_samples - cur_testing_samples\n",
    "        samples = [markov_model.make_short_sentence(max_tweet_size) for i in range(batch_size)]\n",
    "        \n",
    "        for sample in samples:\n",
    "            important_words_dict = {}\n",
    "            contains_important_word = False\n",
    "            if sample is None:\n",
    "                continue\n",
    "            for word in sample.split():\n",
    "                word_label = get_word_label(word)\n",
    "                if word_label is not None:\n",
    "                    important_words_dict[word_label] = important_words_dict.get(word_label, list()) + [word]\n",
    "                    contains_important_word = True\n",
    "            if (contains_important_word):\n",
    "                print('------------------')\n",
    "                print('\\n| [New Sample]')\n",
    "                print('| \\tText: {}'.format(sample))\n",
    "                print('| [Analysis results]')\n",
    "                for label, word_list in important_words_dict.items():\n",
    "                    print('| \\t{}: {}'.format(label, word_list))\n",
    "                print('| [Verification]')\n",
    "                n_city_names = get_int_input('| \\t[1/6] # City Names: ')\n",
    "                n_country_names = get_int_input('| \\t[2/6] # Country Names: ')\n",
    "                n_country_nationalities = get_int_input('| \\t[3/6] # Nationalities: ')\n",
    "                n_religion_names = get_int_input('| \\t[4/6] # Religion names: ')\n",
    "                n_religion_affiliations = get_int_input('| \\t[5/6] # Religious affiliations: ')\n",
    "                n_currency_names = get_int_input('| \\t[6/6] # Currency names: ')\n",
    "                \n",
    "                n_param_sum = n_city_names + n_country_names + n_country_nationalities + n_religion_names + n_religion_affiliations + n_currency_names\n",
    "                if (n_param_sum > 0 or random.randint(0,100) <= unnecessary_sample_retention_percent):\n",
    "                    testing_sample_dict[cur_testing_samples] = {\n",
    "                        'Text': sample,\n",
    "                        'City Names': n_city_names,\n",
    "                        'Country Names': n_country_names,\n",
    "                        'Country Nationalities': n_country_nationalities,\n",
    "                        'Religion Names': n_religion_names,\n",
    "                        'Religion Affiliations': n_religion_affiliations,\n",
    "                        'Currency Names': n_currency_names\n",
    "                    }\n",
    "                    cur_testing_samples += 1\n",
    "                    print('[Result]')\n",
    "                    print('\\tSAVED ({}/{})'.format(cur_testing_samples, max_testing_samples))\n",
    "                else:\n",
    "                    print('[Result]')\n",
    "                    print('\\tDISCARDED')\n",
    "    return testing_sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_auto_religion_testing_samples_dict(max_testing_samples):\n",
    "    # Define number of sentences to generate\n",
    "    cur_testing_samples = 0\n",
    "\n",
    "    testing_sample_dict = {}\n",
    "    while len(testing_sample_dict.keys()) < max_testing_samples:\n",
    "        batch_size = max_testing_samples - cur_testing_samples\n",
    "        samples = [markov_model.make_short_sentence(max_tweet_size) for i in range(batch_size)]\n",
    "        \n",
    "        for sample in samples:\n",
    "            important_words_dict = {}\n",
    "            contains_important_word = False\n",
    "            if sample is None:\n",
    "                continue\n",
    "            for word in sample.split():\n",
    "                word_label = get_word_label(word)\n",
    "                if word_label in ['Religion Names', 'Religion Affiliations']:\n",
    "                    important_words_dict[word_label] = important_words_dict.get(word_label, list()) + [word]\n",
    "                    contains_important_word = True\n",
    "            if (contains_important_word):\n",
    "                print('\\n---Sample----------')\n",
    "                print('| [Text]')\n",
    "                print('| \\t{}'.format(sample))\n",
    "                print('| [Analysis results]')\n",
    "                for label, word_list in important_words_dict.items():\n",
    "                    print('| \\t{}: {}'.format(label, word_list))\n",
    "                print('| [Verification]')\n",
    "                \n",
    "                n_religion_names = len(important_words_dict.get('Religion Names', list()))\n",
    "                n_religion_affiliations = len(important_words_dict.get('Religion Affiliations', list()))\n",
    "                n_param_sum = len(important_words_dict)\n",
    "                if (n_param_sum > 0):\n",
    "                    testing_sample_dict[cur_testing_samples] = {\n",
    "                        'Text': sample,\n",
    "                        'City Names': 0,\n",
    "                        'Country Names': 0,\n",
    "                        'Country Nationalities': 0,\n",
    "                        'Religion Names': n_religion_names,\n",
    "                        'Religion Affiliations': n_religion_affiliations,\n",
    "                        'Currency Names': 0\n",
    "                    }\n",
    "                    cur_testing_samples += 1\n",
    "                    print('| [Result]')\n",
    "                    print('| \\tSAVED ({}/{})'.format(cur_testing_samples, max_testing_samples))\n",
    "                else:\n",
    "                    print('| [Result]')\n",
    "                    print('| \\tDISCARDED')\n",
    "                print('------------------')\n",
    "    return testing_sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: And having kissed Denisov he ran out of the room to change her costume.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Next day, overtaking the army, he went in a carriage to to the house occupied by Kutuzov, asked for Bolkonski.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['a']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: When the integument gives way at the same time, was in splendid condition.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['same']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Growth was almost exclusively driven by exports - particularly of electronics - remain a significant driver of the economy.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'a', 'of', 'economy.']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: When the stagnant fluid is got rid of by blistering, by tapping, or by incision and drainage.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['is', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Hungary held its first multiparty election since World War II through its tourist industry.\n",
      "| [Analysis results]\n",
      "| \tCountry Names: ['Hungary']\n",
      "| \tCity Names: ['since']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: 1\n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (1/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: He declared himself to be in a most remarkable situation--one in which he was now a prisoner, sailing away, never more to return.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['a', 'most', 'a', 'never']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: =Assumption and Funding of State Debts.=--Hamilton then turned to the crowd of generals and officers surrounding him.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: 195 Tonga 39,960 2007 196 Isle of Man 4.38 2010 est.\n",
      "| [Analysis results]\n",
      "| \tCountry Names: ['Tonga']\n",
      "| \tCity Names: ['of', 'Man']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: 1\n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (2/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: When the stagnant fluid is got rid of by blistering, by tapping, or by incision and drainage.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['is', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: It took on the form of a powder, may be employed in a similar manner.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'a', 'a']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: CHAPTER XIX The attack of the Sixth Chasseurs in fine order.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (3/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: If it is intended to preserve a portion of tissue from one part of the body to infection, and this would appear to be the warmest partisans.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['is', 'a', 'of', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (4/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Even after the abolition of slavery, and one of the highest rates in Africa.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (5/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Shouts of approval were heard from the crowd around, and at the same time, a large proportion of urates.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'same', 'a', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: This letter never reached Fontaine, but was, instead, made the subject of a popular outcry against the President and the judges.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['never', 'Fontaine,', 'of', 'a']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: My attention was speedily drawn, as I have already explained, has got out of gear.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['as', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: You fear and yet long to cross that line, and know that sooner or later he would have to relinquish them.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['long', 'line,']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: #Trigeminal Neuralgia.#--A severe form of epileptiform neuralgia occurs in the branches of the United States of America the twelfth.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'of', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: 1\n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (6/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: In 1860, Spain occupied northern Morocco and ushered in a period of ethnic and political unrest.\n",
      "| [Analysis results]\n",
      "| \tCountry Names: ['Spain', 'Morocco']\n",
      "| \tCity Names: ['a', 'of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: 2\n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (7/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: _Complications._--When the varix is of long standing, the skin in the axilla, or in the mouth.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['is', 'of', 'long']\n",
      "| [Verification]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Mongolia settled its $11 billion debt with Russia at the end of 2009 stood at roughly 2,000.\n",
      "| [Analysis results]\n",
      "| \tCountry Names: ['Mongolia', 'Russia']\n",
      "| \tCity Names: ['of']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: 2\n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (8/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: She valued the company of those to whom he had given a shirt to sew was in that shed.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['of', 'a']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: In a second note, made public on June 11, the position of the hands of British commissioners and diplomats.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['a', 'of', 'of']\n",
      "| \tCountry Nationalities: ['British']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: 1\n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (9/10)\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: Pierre's confusion had now almost vanished, but at the same time the temperature is low, a grave prognosis is indicated.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['same', 'is', 'a', 'grave', 'is']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: It is very dangerous and wicked to have anything to do with a young lady seemed to him impossible.\n",
      "| [Analysis results]\n",
      "| \tCity Names: ['is', 'a', 'young']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: \n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tDISCARDED\n",
      "------------------\n",
      "\n",
      "| [New Sample]\n",
      "| \tText: CHAPTER XXIX When the French officer went into the room where Khvostikov and Makarin were sitting.\n",
      "| [Analysis results]\n",
      "| \tCountry Nationalities: ['French']\n",
      "| [Verification]\n",
      "| \t[1/6] # City Names: \n",
      "| \t[2/6] # Country Names: \n",
      "| \t[3/6] # Nationalities: 1\n",
      "| \t[4/6] # Religion names: \n",
      "| \t[5/6] # Religious affiliations: \n",
      "| \t[6/6] # Currency names: \n",
      "[Result]\n",
      "\tSAVED (10/10)\n"
     ]
    }
   ],
   "source": [
    "sample_dict = generate_testing_samples_dict(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>City Names</th>\n",
       "      <th>Country Names</th>\n",
       "      <th>Country Nationalities</th>\n",
       "      <th>Religion Names</th>\n",
       "      <th>Religion Affiliations</th>\n",
       "      <th>Currency Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hungary held its first multiparty election sin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195 Tonga 39,960 2007 196 Isle of Man 4.38 201...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAPTER XIX The attack of the Sixth Chasseurs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If it is intended to preserve a portion of tis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Even after the abolition of slavery, and one o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  City Names  \\\n",
       "0  Hungary held its first multiparty election sin...           0   \n",
       "1  195 Tonga 39,960 2007 196 Isle of Man 4.38 201...           0   \n",
       "2  CHAPTER XIX The attack of the Sixth Chasseurs ...           0   \n",
       "3  If it is intended to preserve a portion of tis...           0   \n",
       "4  Even after the abolition of slavery, and one o...           0   \n",
       "\n",
       "   Country Names  Country Nationalities  Religion Names  \\\n",
       "0              1                      0               0   \n",
       "1              1                      0               0   \n",
       "2              0                      0               0   \n",
       "3              0                      0               0   \n",
       "4              0                      0               0   \n",
       "\n",
       "   Religion Affiliations  Currency Names  \n",
       "0                      0               0  \n",
       "1                      0               0  \n",
       "2                      0               0  \n",
       "3                      0               0  \n",
       "4                      0               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.DataFrame.from_dict(sample_dict, orient='index')\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define file path for output\n",
    "test_samples_file = 'data/parsed/markov_text_files/test_samples_generic_2.csv'\n",
    "\n",
    "sample_df.to_csv(test_samples_file, encoding='utf-8', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
