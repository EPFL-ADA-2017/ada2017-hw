{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "from calendar import monthrange\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_NAME_COLUMN_DATE = 'Date'\n",
    "DEFAULT_NAME_COLUMN_DESCRIPTION = 'Description'\n",
    "DEFAULT_NAME_COLUMN_TOTAL = 'Totals'\n",
    "DEFAULT_NAME_COLUMN_COUNTRY = 'Country'\n",
    "\n",
    "DEFAULT_NAME_ROW_DESCRIPTION_NEW_CASES = 'New cases'\n",
    "DEFAULT_NAME_ROW_DESCRIPTION_NEW_DEATHS = 'New deaths'\n",
    "\n",
    "DEFAULT_DATA_FORMAT = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize_date(date, original_formats):\n",
    "    '''\n",
    "    Transform a date specified in a string with a certain original\n",
    "    format into a string with the date in the default format.\n",
    "    '''\n",
    "    date_rep = None\n",
    "    try:\n",
    "        date_rep = datetime.datetime.strptime(date, original_formats[0])\n",
    "    except ValueError:\n",
    "        date_rep = datetime.datetime.strptime(date, original_formats[1])\n",
    "    return date_rep.strftime(DEFAULT_DATA_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_daily_from_cum(np_list):\n",
    "    '''\n",
    "    Given a list of accumulated data, calculate the data for each day.\n",
    "    It assumes ordered data.\n",
    "    '''\n",
    "    last_known_n = -1\n",
    "    final_list = list()\n",
    "    for i, elem in np_list.iteritems():\n",
    "        #elem = float(elem)\n",
    "        if (math.isnan(elem)):\n",
    "            final_list.append(0)\n",
    "        else:\n",
    "            if (last_known_n == -1):\n",
    "                final_list.append(0)\n",
    "            else:\n",
    "                final_list.append(elem - last_known_n)\n",
    "            last_known_n = elem\n",
    "    return np.array(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definitions of the basic schema and formats for the given dataset is stored in the following dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_keys = ['guinea', 'liberia', 'sl']\n",
    "paths = {x: DATA_FOLDER + '/ebola/'+ x + '_data' for x in country_keys}\n",
    "countries = {'guinea': 'Guinea', 'liberia': 'Liberia', 'sl': 'Sierra Leone'}\n",
    "\n",
    "wanted_columns = {'guinea': ['Date', 'Description', 'Totals'],\n",
    "                      'liberia': ['Date', 'Variable', 'National'],\n",
    "                      'sl': ['date', 'variable', 'National']}\n",
    "\n",
    "date_original_formats = {'guinea': ['%Y-%m-%d', '%y-%m-%d'],\n",
    "                         'liberia': ['%m/%d/%Y', '%m/%d/%y'],\n",
    "                         'sl': ['%Y-%m-%d', '%y-%m-%d']}\n",
    "dataframe_list = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in country_keys:\n",
    "    temp_list = []\n",
    "    all_files = glob.glob(paths[i] + '/*.csv')\n",
    "    for file in all_files:\n",
    "        temp_df = pd.read_csv(file)\n",
    "        temp_list.append(temp_df)\n",
    "    dataframe_list[i] = pd.concat(temp_list)\n",
    "    \n",
    "    # Format dates and order dataframes by date\n",
    "    dataframe_list[i][wanted_columns[i][0]] = np.array([sanitize_date(x, date_original_formats[i])\n",
    "                                                        for x in dataframe_list[i][wanted_columns[i][0]]])\n",
    "    \n",
    "    dataframe_list[i][wanted_columns[i][0]] = pd.to_datetime(dataframe_list[i][wanted_columns[i][0]])\n",
    "    dataframe_list[i].sort_values(by=wanted_columns[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the parsing processes is to obtain a *standard* datataset for each country. We want to extract the useful data for our task while reorganizing the schema and data format to develop a general coherence.\n",
    "\n",
    "***N.B.*** The resulting datatframe do not have the indexing reformatted. Since those are temporary results that will later be concatenated in a single dataframe, we decided to handle the indexing after this operation.\n",
    "\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to parse the Guinea datatset we considered the variables ```New deaaths registered``` (or ```New deaths registered today``` when it was used instead of the previous one) and ```Total new cases registered so far```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_guinea_files():\n",
    "    # Select certain column from the CSV formatted files\n",
    "    parsed_guinea_df = dataframe_list['guinea'][wanted_columns['guinea']]\n",
    "    wanted_row_list = ['Total new cases registered so far',\n",
    "                       'New deaths registered', \n",
    "                       'New deaths registered today']\n",
    "    \n",
    "    # Select all the rows that match desired names for 'Description' column\n",
    "    parsed_guinea_df = parsed_guinea_df[parsed_guinea_df['Description'].isin(wanted_row_list)]\n",
    "    \n",
    "    # Rename every row value for 'Description' column \n",
    "    parsed_guinea_df.loc[parsed_guinea_df['Description'] ==\n",
    "                         wanted_row_list[0], 'Description'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_CASES\n",
    "    \n",
    "    parsed_guinea_df.loc[parsed_guinea_df['Description'] ==\n",
    "                         wanted_row_list[1], 'Description'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_DEATHS\n",
    "    \n",
    "    parsed_guinea_df.loc[parsed_guinea_df['Description'] ==\n",
    "                         wanted_row_list[2], 'Description'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_DEATHS\n",
    "    \n",
    "    # Add 'Country' column to dataframe\n",
    "    parsed_guinea_df[DEFAULT_NAME_COLUMN_COUNTRY] = countries['guinea']\n",
    "    \n",
    "    return parsed_guinea_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_guinea_files().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to parse the Liberia dataset we considered the ```Newly reported deaths``` variable. To handle the new cases data we, on the other hand, had to do some manipulations.\n",
    "\n",
    "The new cases comes in three different variables (```New Case/s (Suspected)```, ```New Case/s (Probable)``` and ```New Case/s (confirmed)```) that have to be summed up to obtain the total daily value.\n",
    "\n",
    "The data comes with strangely big new casses values for the last days of the report. We concluded that those numbers couldn't be correct. As we found a correlation between those values and th3 total new cases accomulator for the past days, we assumed the data as been inputted on the wrong part of the table. Some missing new cases data were therefore calculated from the daily difference of those totals accumulator during the last month of the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_liberia_files():\n",
    "    # Select certain columns from the CSV formatted files\n",
    "    liberia_df = dataframe_list['liberia'][wanted_columns['liberia']]\n",
    "\n",
    "    wanted_row_list = ['New Case/s (Suspected)',\n",
    "                       'New Case/s (Probable)',\n",
    "                       'New case/s (confirmed)',\n",
    "                       'Newly reported deaths',\n",
    "                       'Total suspected cases',\n",
    "                       'Total probable cases',\n",
    "                       'Total confirmed cases']\n",
    "\n",
    "    # Create temporary dataframe for new case entries\n",
    "    # (with every row that matches the desired 'Variables' column value)\n",
    "    liberia_df_new_cases_cum_1 = liberia_df[liberia_df['Variable'].isin(wanted_row_list[4:7])]\n",
    "    liberia_df_new_cases_cum_1 = liberia_df_new_cases_cum_1[liberia_df_new_cases_cum_1['Date'].map(\n",
    "        lambda x: x.month == 12 and x.day <= 3)]\n",
    "    liberia_df_new_cases_cum_1 = liberia_df_new_cases_cum_1.groupby('Date').sum()\n",
    "    \n",
    "    liberia_df_new_cases_cum_2 = liberia_df[liberia_df['Variable'].isin(wanted_row_list[0:3])]\n",
    "    liberia_df_new_cases_cum_2 = liberia_df_new_cases_cum_2[liberia_df_new_cases_cum_2['Date'].map(\n",
    "        lambda x: x.month == 12 and x.day > 3)]\n",
    "    liberia_df_new_cases_cum_2 = liberia_df_new_cases_cum_2.groupby('Date').sum()\n",
    "    \n",
    "    liberia_df_new_cases_cum = pd.concat([liberia_df_new_cases_cum_1, liberia_df_new_cases_cum_2])\n",
    "\n",
    "    \n",
    "    liberia_df_new_cases_cum['National'] = estimate_daily_from_cum(liberia_df_new_cases_cum['National'])\n",
    "    \n",
    "    liberia_df_new_cases = liberia_df[liberia_df['Variable'].isin(wanted_row_list[0:3])]\n",
    "    liberia_df_new_cases = liberia_df_new_cases[liberia_df_new_cases['Date'].map(\n",
    "        lambda x: x.month != 12)]\n",
    "    \n",
    "    liberia_df_new_cases = pd.concat([liberia_df_new_cases, liberia_df_new_cases_cum])\n",
    "    \n",
    "    # Sum all of the values for 'Probable', 'Variable' and 'Confirmed' new cases\n",
    "    liberia_df_new_cases = liberia_df_new_cases.groupby('Date').sum()\n",
    "\n",
    "    liberia_df_new_cases['Date'] = liberia_df_new_cases.index\n",
    "    liberia_df_new_cases['Variable'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_CASES\n",
    "    \n",
    "    # Create temporary dataframe for new deaths entries\n",
    "    liberia_df_new_deaths = liberia_df[liberia_df['Variable'] == wanted_row_list[3]]\n",
    "    liberia_df_new_deaths['Variable'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_DEATHS\n",
    "    \n",
    "    # Create new dataframe with new deaths and cases (concatenating the two temporary)\n",
    "    parsed_liberia_df = pd.concat([liberia_df_new_cases, liberia_df_new_deaths])\n",
    "    \n",
    "    parsed_liberia_df.rename(columns={'Date': DEFAULT_NAME_COLUMN_DATE,\n",
    "                                      'Variable': DEFAULT_NAME_COLUMN_DESCRIPTION,\n",
    "                                      'National': DEFAULT_NAME_COLUMN_TOTAL}, inplace=True)\n",
    "\n",
    "    # Add 'Country' column to dataframe\n",
    "    parsed_liberia_df[DEFAULT_NAME_COLUMN_COUNTRY] = countries['liberia']\n",
    "    \n",
    "    return parsed_liberia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_liberia_files().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to parse the Sierra Leone datatset we followed similar steps as for the Liberia. The new cases value has been computed as the sum of the different variables of the table (```new_noncase```, ```new_suspected```, ```new_probable``` and ```new_confirmed```). \n",
    "\n",
    "Since the dataset only had total accomulators for the new death variable we calculated them as the difference between days, as previously done with Liberia. The possible missing data for this operation has been handled by setting them to zero, while keeping the the same delta for known points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_sierra_files():\n",
    "    # Select certain columns from the CSV formatted files\n",
    "    parsed_sierra_df = dataframe_list['sl'][wanted_columns['sl']]\n",
    "    \n",
    "    wanted_row_list = ['new_noncase', 'new_suspected', 'new_probable', 'new_confirmed',\n",
    "                       'death_confirmed', 'death_probable', 'death_suspected']\n",
    "    \n",
    "    # Create temporary dataframe for new case entries\n",
    "    # (with every row that matches the desired 'variables' column value)\n",
    "    sierra_df_new_cases = parsed_sierra_df[parsed_sierra_df['variable'].isin(wanted_row_list[0:4])]\n",
    "    \n",
    "    # Sum all of the values for 'Probable', 'Variable', 'Confirmed' and 'Noncase' new cases\n",
    "    sierra_df_new_cases = sierra_df_new_cases.groupby('date')['National'].apply(\n",
    "        lambda x: np.array([float(y) for y in x]).sum()).to_frame()\n",
    "    \n",
    "    sierra_df_new_cases['date'] = sierra_df_new_cases.index\n",
    "    sierra_df_new_cases['variable'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_CASES\n",
    "    \n",
    "    # Create temporary dataframe for new deaths' accumulator entries\n",
    "    sierra_df_new_deaths_cum = parsed_sierra_df[parsed_sierra_df['variable'].isin(wanted_row_list[4:7])]\n",
    "    \n",
    "    # Sum all of the values for 'Probable', 'Suspected' and 'Confirmed' new death accumulators\n",
    "    sierra_df_new_deaths_cum = sierra_df_new_deaths_cum.groupby('date')['National'].apply(\n",
    "        lambda x: np.array([float(y) for y in x]).sum()).to_frame()\n",
    "    \n",
    "    sierra_df_new_deaths_cum['date'] = sierra_df_new_deaths_cum.index\n",
    "    sierra_df_new_deaths_cum['variable'] = 'New deaths accumulator'\n",
    "    \n",
    "    # \n",
    "    sierra_df_new_deaths_cum['National'] = estimate_daily_from_cum(sierra_df_new_deaths_cum['National'])\n",
    "    sierra_df_new_deaths_cum['variable'] = DEFAULT_NAME_ROW_DESCRIPTION_NEW_DEATHS\n",
    "    \n",
    "    #\n",
    "    parsed_sierra_df = pd.concat([sierra_df_new_cases, sierra_df_new_deaths_cum])\n",
    "    \n",
    "    parsed_sierra_df.rename(columns={'date': DEFAULT_NAME_COLUMN_DATE,\n",
    "                                     'variable': DEFAULT_NAME_COLUMN_DESCRIPTION,\n",
    "                                     'National': DEFAULT_NAME_COLUMN_TOTAL}, inplace=True)\n",
    "    \n",
    "    # Add 'Country' column to dataframe\n",
    "    parsed_sierra_df[DEFAULT_NAME_COLUMN_COUNTRY] = countries['sl']\n",
    "    \n",
    "    return parsed_sierra_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_sierra_files().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the parsed country datatset into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_df = pd.concat([parse_guinea_files(), parse_liberia_files(), parse_sierra_files()])\n",
    "complete_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after handling the Nan troubles during the parsing for some aspects, we might still have some to manage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[complete_df[DEFAULT_NAME_COLUMN_TOTAL].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume NaN values are 0\n",
    "complete_df = complete_df.fillna(0)\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the difference in the number of deaths between 2014-09-30 and 2014-10-01 is negative. We decided to ignore this negative number of deaths, since it is ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Maybe remove the row with -18 deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate for each country, the daily average per month of new cases and deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = complete_df.groupby(by=[complete_df.Country, complete_df.Description, [x.month for x in complete_df.Date]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculated_average_df = pd.DataFrame()\n",
    "\n",
    "for ((country, description, month), values) in grouped:\n",
    "    days_in_month = monthrange(2014, month)[1]\n",
    "    entry = {'Country':country, \n",
    "             'Description':description, \n",
    "             'Month':month, \n",
    "             'Average':values[DEFAULT_NAME_COLUMN_TOTAL].apply(lambda x: float(x) / days_in_month).sum()}\n",
    "    calculated_average_df = calculated_average_df.append([entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "death_average_df = calculated_average_df[calculated_average_df['Description'] == DEFAULT_NAME_ROW_DESCRIPTION_NEW_DEATHS]\n",
    "cases_average_df = calculated_average_df[calculated_average_df['Description'] == DEFAULT_NAME_ROW_DESCRIPTION_NEW_CASES]\n",
    "\n",
    "calculated_average_df = pd.merge(death_average_df, cases_average_df, on=['Country', 'Month'])\n",
    "calculated_average_df.drop(['Description_x', 'Description_y'], axis=1, inplace=True)\n",
    "calculated_average_df = calculated_average_df.rename(columns={'Average_x': 'Death monthly average',\n",
    "                                                              'Average_y': 'Cases monthly average'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result if shown in the following table. For each country we calculated the avarage for the new deaths entries as well as the new cases entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_average_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the results for a final visualisation of the obtained data. First by country alone in the following bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, group in calculated_average_df.groupby('Country'):\n",
    "    group.plot(x='Month', title=title, kind=\"bar\", figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly as an unique bar chart for all the results in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_average_df.plot.bar(x=['Month','Country'], figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by importing the nine tables in one single big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(DATA_FOLDER + '/microbiome' + '/MID*.xls')\n",
    "raw_df = pd.DataFrame()\n",
    "\n",
    "for file in all_files:\n",
    "    file_name = file[file.rfind('/')+1:file.rfind('.')]\n",
    "    temp_df = pd.read_excel(file, header=None)\n",
    "    temp_df['BARCODE'] = file_name\n",
    "    raw_df = raw_df.append(temp_df)\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the imported the metadata table in another dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_excel(DATA_FOLDER+'/microbiome'+'/metadata.xls')\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datatframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to obtain a single dataframe for the given data. We will need to obtain a table of the following format:\n",
    "\n",
    "| Description | Group | Tissue | Stool | Other |\n",
    "|-------------|-------|--------|-------|-------|\n",
    "|             |       |        |       |       |\n",
    "|             |       |        |       |       |\n",
    "|             |       |        |       |       |\n",
    "\n",
    "\n",
    "We will fill-in the last three collumns with the sample date we have in the given datatframes. The column will be chosen according to what the metadata provides. The same idea will be followed to fill-in the Group collumn with the correct information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create three dataframe containing the metadata informations for a single Sample type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stool_metadata_df = metadata_df[metadata_df['SAMPLE'] == 'stool']\n",
    "tissue_metadata_df = metadata_df[metadata_df['SAMPLE'] == 'tissue']\n",
    "na_metadata_df = metadata_df[metadata_df['SAMPLE'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create three dataframes for the different samples according to what we have in the metatada dataframes obtained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.merge(raw_df, metadata_df[['BARCODE', 'GROUP']], on=['BARCODE'])\n",
    "raw_df.rename(columns={0: 'Description', 1: 'Sample'}, inplace=True)\n",
    "\n",
    "stool_df = raw_df[raw_df['BARCODE'].isin(list(stool_metadata_df['BARCODE']))].drop('BARCODE', axis=1)\n",
    "stool_df.rename(columns={'Sample': 'Stool'}, inplace=True)\n",
    "              \n",
    "tissue_df = raw_df[raw_df['BARCODE'].isin(list(tissue_metadata_df['BARCODE']))].drop('BARCODE', axis=1)\n",
    "tissue_df.rename(columns={'Sample': 'Tissue'}, inplace=True)\n",
    "              \n",
    "na_df = raw_df[raw_df['BARCODE'].isin(list(na_metadata_df['BARCODE']))].drop('BARCODE', axis=1)\n",
    "na_df.rename(columns={'Sample': 'Other'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stool_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge those three temporary dataframes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(stool_df, tissue_df, how='outer', on=['Description', 'GROUP'])\n",
    "merged_df = pd.merge(merged_df, na_df, how='outer', on=['Description', 'GROUP'])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the task, we fill the Nan values of the dataset with the 'unknown' value and we clear the general format of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill of the 'unknown' value for NaNs\n",
    "merged_df.fillna('unknown', inplace=True)\n",
    "\n",
    "# Final cleaning up of the table schema\n",
    "merged_df.rename(columns={'GROUP':'Group'}, inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
