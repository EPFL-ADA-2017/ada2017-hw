{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will extract interesting information from www.topuniversities.com and www.timeshighereducation.com, two platforms that maintain a global ranking of worldwide universities. This ranking is not offered as a downloadable dataset, so you will have to find a way to scrape the information we need! You are not allowed to download manually the entire ranking -- rather you have to understand how the server loads it in your browser. For this task, Postman with the Interceptor extension can help you greatly. We recommend that you watch this brief tutorial to understand quickly how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constans definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QS_RANKING_URL = 'https://www.topuniversities.com/university-rankings/world-university-rankings/2018'\n",
    "\n",
    "TIMES_RANKING_URL = 'http://timeshighereducation.com/world-university-rankings/2018/world-ranking'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import dryscrape\n",
    "\n",
    "session = dryscrape.Session()\n",
    "session.visit(QS_RANKING_URL)\n",
    "response = session.body()\n",
    "#soup = BeautifulSoup(response)\n",
    "#soup.find(id=\"intro-text\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(QS_RANKING_URL) \n",
    "\n",
    "time.sleep(3)\n",
    "print(driver.find_element_by_id(\"content\").text)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General use functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_html_parser(url):\n",
    "    '''\n",
    "    Function to build a parser object of type BeautifulSoup\n",
    "    \n",
    "    url      the webpage url to which send a get request to\n",
    "    \n",
    "    return   a parser of the given webpage\n",
    "    '''\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    page_body = r.text\n",
    "    \n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Obtain the 200 top-ranking universities in www.topuniversities.com (ranking 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY SOLUTION ! CHECK BELOW FOR THE EVOLUTION\n",
    "\n",
    "file = open(\"qs.htm\", \"r\")\n",
    "page_body = file.read()\n",
    "\n",
    "soup = BeautifulSoup(page_body, 'html.parser')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "soup = build_html_parser(QS_RANKING_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking is presented as a ```<tr>``` element for each university inside a ```<table>``` tag for them all. Each page has a table with 25 rows (university) each. Each row element has an unique id assigned that matched the pattern cid-xxx (with xxx the specific entry number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of row elements matching cid-xxx pattern\n",
    "university_wrappers = soup.findAll(\"tr\", {\"id\" : lambda x: x and x.startswith('cid-')})\n",
    "\n",
    "print('Total number of items: {0}'.format(len(university_wrappers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_detail_page(url_detail):\n",
    "    '''\n",
    "    Function that parses the missing informations from the detail page of the university from the QS website\n",
    "    \n",
    "    Return   a dictionary with all the data found as integers values\n",
    "    '''\n",
    "    \n",
    "    # Build a parser for the detail page\n",
    "    soup = build_html_parser(url_detail)\n",
    "    \n",
    "    # Obtain and clean up the total faculty member value\n",
    "    faculty_member_total = soup.find('div', class_='total faculty').find('div', class_='number').text\n",
    "    faculty_member_total = faculty_member_total.strip('\\n').replace(',','')\n",
    "    \n",
    "    # Obtain and clean up the international faculty member value\n",
    "    faculty_member_inter = soup.find('div', class_='inter faculty').find('div', class_='number').text.strip('\\n')\n",
    "    faculty_member_inter = faculty_member_inter.strip('\\n').replace(',','')\n",
    "    \n",
    "    # Obtain and clean up the total students value\n",
    "    student_total = soup.find('div', class_='total student').find('div', class_='number').text.strip('\\n')\n",
    "    student_total = student_total.strip('\\n').replace(',','')\n",
    "    \n",
    "    # Obtain and clean up the international students value\n",
    "    student_inter = soup.find('div', class_='total inter').find('div', class_='number').text.strip('\\n')\n",
    "    student_inter = student_inter.strip('\\n').replace(',','')\n",
    "    \n",
    "    # Build a dictionary for the parsed informations\n",
    "    detail_info = {'Total faculty member' : int(faculty_member_total), \n",
    "                   'International faculty member' : int(faculty_member_inter), \n",
    "                   'Total student' : int(student_total), \n",
    "                   'International student' : int(student_inter)\n",
    "                  }\n",
    "    \n",
    "    return detail_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: I have no idea what they mean by region... is it the city? or what?\n",
    "\n",
    "university_list = []\n",
    "for u in university_wrappers:\n",
    "    rank = u.find('span', class_='rank').text  # get the rank value\n",
    "    name = u.find('td', class_='uni').find('a').text # get the name value\n",
    "    country = u.find('img', class_='flag')['alt'] # get the country value\n",
    "        \n",
    "    # Store the parsed information into a dictionary\n",
    "    info = {'Rank': rank, 'Univerisity name': name, 'Country': country}\n",
    "    \n",
    "    # Extend the dictionary with the informations in the detail page\n",
    "    url_detail = u.find('td', class_='uni').find('a')['href']\n",
    "    info.update(parse_detail_page(url_detail))\n",
    "    \n",
    "    university_list.append(info)\n",
    "    \n",
    "    \n",
    "ranking_df = pd.DataFrame.from_dict(university_list)\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking_df.set_index(['Univerisity name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the two required ratios with the help of two auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_facutly_member_ratio(df):\n",
    "    '''\n",
    "    Co\n",
    "    '''\n",
    "    li = list()\n",
    "    for i, row in df.iterrows():\n",
    "        li.append(row['Total faculty member'] / row['Total student'])\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_student_ratio(df):\n",
    "    li = list()\n",
    "    for i, row in df.iterrows():\n",
    "        li.append(row['International student'] / row['Total student'])\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation results are stored in two new colums of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df['Faculty/students ratio'] = compute_facutly_member_ratio( ranking_df )\n",
    "ranking_df['Intern/student ratio'] = compute_student_ratio( ranking_df )\n",
    "\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the dataframe for the ratios computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df[['Faculty/students ratio', 'Intern/student ratio']].plot.bar( figsize=(25, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
