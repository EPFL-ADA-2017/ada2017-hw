{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will extract interesting information from [www.topuniversities.com](http://www.topuniversities.com) and [www.timeshighereducation.com](http://www.timeshighereducation.com), two platforms that maintain a global ranking of worldwide universities. This ranking is not offered as a downloadable dataset, so we scrape the information we need. To understand how the server loads it in the browser, we used Postman with the Interceptor extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Task 1 - Scrape the QS ranking](#Task-1---Scrape-the-QS-ranking)\n",
    "    * [Best universities for ratio between faculty members and students](#Which-are-the-best-universities-in-term-of-ratio-between-faculty-members-and-students-according-to-QS?)\n",
    "    * [Best universities for the international students ratio](#Which-are-the-best-universities-in-term-of-ratio-of-international-students-according-to-QS?)\n",
    "    * [Results by region](#Plot-the-results-from-QS-ranking-aggregating-by-region)\n",
    "    * [Results by country](#Plot-the-results-from-QS-ranking-aggregating-by-country)\n",
    "\n",
    "\n",
    "* [Task 2 - Scrape the Times ranking](#Task-2---Scrape-the-Times-ranking)\n",
    "    * [Best universities for ratio between faculty members and students](#Which-are-the-best-universities-in-term-of-ratio-between-faculty-members-and-students-according-to-Times?)\n",
    "    * [Best universities for the international students ratio](#Which-are-the-best-universities-in-term-of-ratio-of-international-students-according-to-Times?)\n",
    "    * [Results by region](#Plot-the-results-from-Times-ranking-aggregating-by-region)\n",
    "    * [Results by country](#Plot-the-results-from-Times-ranking-aggregating-by-country)\n",
    "    \n",
    "    \n",
    "* [Task 3 - Merge the dataframes](#Task-3---Merge-the-dataframes)\n",
    "\n",
    "\n",
    "* [Task 4 - Exploratory analysis](#Task-4---Exploratory-analysis)\n",
    "\n",
    "\n",
    "* [Task 5 - Exploratory analysis](#Task-5--)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMN_LABEL_RANK = 'Rank'\n",
    "COLUMN_LABEL_REGION = 'Region'\n",
    "COLUMN_LABEL_COUNTRY = 'Country'\n",
    "COLUMN_LABEL_TOTAL_FACULTY = 'Total Faculty'\n",
    "COLUMN_LABEL_TOTAL_STUDENTS = 'Total Students'\n",
    "COLUMN_LABEL_UNIVERSITY_NAME = 'University Name'\n",
    "COLUMN_LABEL_FACULTY_RATIO = 'Total Faculty / Total Student'\n",
    "COLUMN_LABEL_TOTAL_INTERNATIONAL_FACULTY = 'Total International Faculty'\n",
    "COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS = 'Total International Students'\n",
    "COLUMN_LABEL_INTERNATIONAL_RATIO = 'Total International Students / Total Students'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QS_RANKING_JSON = 'https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508104120137'\n",
    "TIMES_RANKING_JSON = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEARCH_REFERENCE_API = 'https://en.wikipedia.org/w/api.php?action=query&titles={0}&prop=revisions&rvprop=content&format=json&indexpageids'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the very first scraping of the QS ranking, we build a dataframe that contains the region for each country. This information will be used to fill in the region column in the Times dataframe.\n",
    "\n",
    "After the first scraping is done, the three dataframes - containing the regions for each country and the two rankings - are serialized in local for future runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    COUNTRY_REGION_METADATA = pd.read_pickle('serial/country_region_metadata.p')\n",
    "except (OSError, IOError) as e:\n",
    "    COUNTRY_REGION_METADATA = pd.DataFrame(columns=[COLUMN_LABEL_REGION])\n",
    "    COUNTRY_REGION_METADATA.to_pickle('serial/country_region_metadata.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of the country-region dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Region\n",
       "United States   North America\n",
       "United Kingdom         Europe\n",
       "Switzerland            Europe\n",
       "Singapore                Asia\n",
       "Australia             Oceania"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRY_REGION_METADATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General use functions definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some helper functions that will be used in the upcoming tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str_number(str_n):\n",
    "    \"\"\"Obtain a string that only contains the numeric information, \n",
    "    dropping any formatting character.\n",
    "    \n",
    "    str_n -- a string containg both numeric and formatting characters\n",
    "    \n",
    "    return a string only with numeric characters\n",
    "    \"\"\"\n",
    "    \n",
    "    return str_n.strip('\\n').strip('%').replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_standard_name(str_name):\n",
    "    \"\"\"Given a name, query the WikiData database to obtain the WikiData formatted entry.\n",
    "    The function takes care of cleaning up the string in order to ease\n",
    "    the research process.\n",
    "    \n",
    "    str_name -- the query to search in the WikiData\n",
    "    \n",
    "    return the WikiData formatted entry of the query value if found,\n",
    "    the cleaned up version of the passed value otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    str_name = str_name.split(\" - \")[0] # Manage name with - (short)\n",
    "    str_name = str_name.split(\" – \")[0] # Manage name with – (long)\n",
    "    str_name = re.sub('\\(.*?\\)','', str_name) # no brackets\n",
    "    str_name = str_name.strip().replace('&', '%26')\n",
    "    \n",
    "    r = requests.get(SEARCH_REFERENCE_API.format(str_name.strip().replace(' ', '_')))\n",
    "    data = r.json()\n",
    "    \n",
    "    page_id = data['query']['pageids'][0]\n",
    "    \n",
    "    if (page_id == '-1'):\n",
    "        print('Not found :( -> {}'.format(str_name))\n",
    "        \n",
    "        # Manually set a standard name for the only unmatchable university. \n",
    "        # We have a total of 9 unknown sources during the WikiData requests, but only one university appears twice\n",
    "        # and it need to receive a standard name to be merged later on. The other onces could keep their name\n",
    "        if (str_name == \"Scuola Superiore Sant'Anna Pisa di Studi Universitari e di Perfezionamento\"):\n",
    "            found_name = \"Scuola Superiore Sant’Anna\"\n",
    "        else:\n",
    "            found_name = str_name\n",
    "    else:\n",
    "        found_name = data['query']['pages'][page_id]['title']\n",
    "        \n",
    "    return(found_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_country_region_metadata(country, region):\n",
    "    \"\"\"Append a new entry to the global dataframe that relates regions and countries.\n",
    "    \n",
    "    country -- the country to add\n",
    "    region -- the region to add\n",
    "    \"\"\"\n",
    "    \n",
    "    global COUNTRY_REGION_METADATA\n",
    "    \n",
    "    if (country in COUNTRY_REGION_METADATA.index):\n",
    "        return\n",
    "    \n",
    "    new_row = pd.Series(region, index=[COLUMN_LABEL_REGION])\n",
    "    new_row.name = country\n",
    "    \n",
    "    COUNTRY_REGION_METADATA = COUNTRY_REGION_METADATA.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Scrape the QS ranking\n",
    "This task consists on obtaining the 200 top-ranking universities in www.topuniversities.com (ranking 2018). We define the function `scrape_qs_ranking`. Since some of the information is missing from the main page, we need to scrape the remaining data from the details pages for each of the universities in the ranking - this is done using the `parse_detail_page` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_detail_page(url_detail):\n",
    "    \"\"\"Parses information from the detail page of the university from the QS website.\n",
    "\n",
    "    url_detail -- the url of the detail page to scrape\n",
    "\n",
    "    Return a dictionary with all the data found as integers values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build a parser for the detail page\n",
    "    soup = BeautifulSoup(requests.get(url_detail).text, 'html.parser')\n",
    "    \n",
    "    # Obtain and clean up the total faculty member value\n",
    "    try:\n",
    "        faculty_member_total = soup.find('div', class_='total faculty').find('div', class_='number').text\n",
    "        faculty_member_total = clean_str_number(faculty_member_total)\n",
    "    except AttributeError:\n",
    "        faculty_member_total = -1\n",
    "    \n",
    "    \n",
    "    # Obtain and clean up the international faculty member value\n",
    "    try:\n",
    "        faculty_member_inter = soup.find('div', class_='inter faculty').find('div', class_='number').text.strip('\\n')\n",
    "        faculty_member_inter = clean_str_number(faculty_member_inter)\n",
    "    except AttributeError:\n",
    "        faculty_member_inter = -1\n",
    "    \n",
    "    # Obtain and clean up the total students value\n",
    "    try:\n",
    "        student_total = soup.find('div', class_='total student').find('div', class_='number').text.strip('\\n')\n",
    "        student_total = clean_str_number(student_total)\n",
    "    except AttributeError:\n",
    "        student_total = -1\n",
    "    \n",
    "    # Obtain and clean up the international students value\n",
    "    try:\n",
    "        student_inter = soup.find('div', class_='total inter').find('div', class_='number').text.strip('\\n')\n",
    "        student_inter = clean_str_number(student_inter)\n",
    "    except AttributeError:\n",
    "        student_inter = -1\n",
    "    \n",
    "    # Build a dictionary for the parsed informations\n",
    "    detail_info = {COLUMN_LABEL_TOTAL_FACULTY: int(faculty_member_total), \n",
    "                   COLUMN_LABEL_TOTAL_INTERNATIONAL_FACULTY: int(faculty_member_inter), \n",
    "                   COLUMN_LABEL_TOTAL_STUDENTS: int(student_total), \n",
    "                   COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS: int(student_inter)\n",
    "                  }\n",
    "    \n",
    "    return detail_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some work on the Postman Inspector, we found out that the GET Request made to the QS website ended up with multiple attached files to go with the response. One of those files was a JSON with all the infos from the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req = requests.get(QS_RANKING_JSON)\n",
    "data_from_url = req.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such data is stored as a list of dictionaries, as visible in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First cell:\n",
      "{'nid': '294850', 'url': '/universities/massachusetts-institute-technology-mit', 'title': 'Massachusetts Institute of Technology (MIT)', 'logo': '<img src=\"https://www.topuniversities.com/sites/default/files/massachusetts-institute-of-technology-mit_410_small_0.jpg\" alt=\"Massachusetts Institute of Technology (MIT)  Logo\">', 'core_id': '410', 'score': '100', 'rank_display': '1', 'country': 'United States', 'cc': 'US', 'region': 'North America', 'stars': '6', 'guide': '<a href=\"/where-to-study/north-america/united-states/guide\" class=\"guide-link\" target=\"_blank\">United States</a>'}\n",
      "\n",
      "Second cell:\n",
      "{'nid': '297282', 'url': '/universities/stanford-university', 'title': 'Stanford University', 'logo': '<img src=\"https://www.topuniversities.com/sites/default/files/stanford-university_573_small_0.jpg\" alt=\"Stanford University Logo\">', 'core_id': '573', 'score': '98.7', 'rank_display': '2', 'country': 'United States', 'cc': 'US', 'region': 'North America', 'stars': '5', 'guide': '<a href=\"/where-to-study/north-america/united-states/guide\" class=\"guide-link\" target=\"_blank\">United States</a>'}\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print('First cell:')\n",
    "print(data_from_url['data'][0], end='\\n\\n')\n",
    "\n",
    "print('Second cell:')\n",
    "print(data_from_url['data'][1], end='\\n\\n')\n",
    "\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract all the information from both the ranking webpage and the details webpage for each university.\n",
    "\n",
    "There are some universities that have a tie in their positions in the ranking, but we are assuming that there are no ties and that the universities are ordered according to their position in the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_qs_ranking():\n",
    "    \"\"\"Obtain the ranking from the top 200 of QS in a dataframe\n",
    "    \n",
    "    return the dataframe containing all the informations (main and detail page) of QS ranking\n",
    "    \"\"\"\n",
    "    \n",
    "    data = requests.get(QS_RANKING_JSON).json()\n",
    "    university_list = []\n",
    "\n",
    "    # Iterate through the first 200 universities in the list\n",
    "    for i, d in enumerate(data['data'][:200]):\n",
    "    \n",
    "        # Store the parsed information into a dictionary\n",
    "        info = {COLUMN_LABEL_RANK: (i+1),\n",
    "                COLUMN_LABEL_UNIVERSITY_NAME: search_standard_name(d['title']),\n",
    "                COLUMN_LABEL_COUNTRY: d['country'],\n",
    "                COLUMN_LABEL_REGION: d['region']\n",
    "               }\n",
    "        \n",
    "        # Update country-region dataframe if there is new information\n",
    "        update_country_region_metadata(d['country'], d['region'])\n",
    "    \n",
    "        # Extend the dictionary with the informations in the detail page\n",
    "        url_detail = 'https://www.topuniversities.com' +  d['url']\n",
    "        info.update(parse_detail_page(url_detail))\n",
    "        \n",
    "        # Appending university entry\n",
    "        university_list.append(info)\n",
    "    \n",
    "    # After scraping data from QS ranking the metadata dataframe needs to be stored updated\n",
    "    COUNTRY_REGION_METADATA.to_pickle('serial/country_region_metadata.p')\n",
    "    \n",
    "    qs_ranking_df = pd.DataFrame.from_dict(university_list)\n",
    "    return qs_ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the functions we need, we scrape the webpage and serialize the dataframe. If the serialized object already exists, we deserialize it and do not scrape the page again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Region</th>\n",
       "      <th>Total Faculty</th>\n",
       "      <th>Total International Faculty</th>\n",
       "      <th>Total International Students</th>\n",
       "      <th>Total Students</th>\n",
       "      <th>University Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>2982</td>\n",
       "      <td>1679</td>\n",
       "      <td>3717</td>\n",
       "      <td>11067</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>2</td>\n",
       "      <td>North America</td>\n",
       "      <td>4285</td>\n",
       "      <td>2042</td>\n",
       "      <td>3611</td>\n",
       "      <td>15878</td>\n",
       "      <td>Stanford University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>North America</td>\n",
       "      <td>4350</td>\n",
       "      <td>1311</td>\n",
       "      <td>5266</td>\n",
       "      <td>22429</td>\n",
       "      <td>Harvard University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>4</td>\n",
       "      <td>North America</td>\n",
       "      <td>953</td>\n",
       "      <td>350</td>\n",
       "      <td>647</td>\n",
       "      <td>2255</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5</td>\n",
       "      <td>Europe</td>\n",
       "      <td>5490</td>\n",
       "      <td>2278</td>\n",
       "      <td>6699</td>\n",
       "      <td>18770</td>\n",
       "      <td>University of Cambridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country  Rank         Region  Total Faculty  \\\n",
       "0   United States     1  North America           2982   \n",
       "1   United States     2  North America           4285   \n",
       "2   United States     3  North America           4350   \n",
       "3   United States     4  North America            953   \n",
       "4  United Kingdom     5         Europe           5490   \n",
       "\n",
       "   Total International Faculty  Total International Students  Total Students  \\\n",
       "0                         1679                          3717           11067   \n",
       "1                         2042                          3611           15878   \n",
       "2                         1311                          5266           22429   \n",
       "3                          350                           647            2255   \n",
       "4                         2278                          6699           18770   \n",
       "\n",
       "                         University Name  \n",
       "0  Massachusetts Institute of Technology  \n",
       "1                    Stanford University  \n",
       "2                     Harvard University  \n",
       "3     California Institute of Technology  \n",
       "4                University of Cambridge  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    qs_ranking_df = pd.read_pickle('serial/qs_save.p')\n",
    "except (OSError, IOError) as e:\n",
    "    qs_ranking_df = scrape_qs_ranking()\n",
    "    qs_ranking_df.to_pickle('serial/qs_save.p')\n",
    "    \n",
    "qs_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we set a meaningful unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'COLUMN_NAME_UNIVERSITY_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9b62405d1a53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqs_ranking_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOLUMN_NAME_UNIVERSITY_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'COLUMN_NAME_UNIVERSITY_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "qs_ranking_df.set_index(COLUMN__UNIVERSITY_NAME, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best universities in terms of ratio between faculty members and students according to QS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the ratio between faculty member and students\n",
    "qs_ranking_df[COLUMN_LABEL_FACULTY_RATIO] = qs_ranking_df[COLUMN_LABEL_TOTAL_FACULTY] / qs_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS]\n",
    "\n",
    "# Clean up the computation taking care of unknown values (previously set at -1)\n",
    "qs_fsratio_defined = (qs_ranking_df[COLUMN_LABEL_TOTAL_FACULTY] != -1) | (qs_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS] != -1)\n",
    "qs_ranking_df.loc[~qs_fsratio_defined, COLUMN_LABEL_FACULTY_RATIO] = float('nan')\n",
    "\n",
    "# Define a dataset for the result computation\n",
    "qs_faculty_students_rank_df = qs_ranking_df[[COLUMN_LABEL_COUNTRY, COLUMN_LABEL_REGION, COLUMN_LABEL_TOTAL_FACULTY,\n",
    "                                             COLUMN_LABEL_TOTAL_STUDENTS, COLUMN_LABEL_FACULTY_RATIO]]\n",
    "qs_faculty_students_rank_df = qs_faculty_students_rank_df.sort_values(COLUMN_LABEL_FACULTY_RATIO, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the ratio, we plot it for the 20 universities with the highest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_faculty_students_rank_df[:20][COLUMN_LABEL_FACULTY_RATIO].plot(kind='barh', figsize=(10,7), color='green')\n",
    "\n",
    "plt.title('Top 20 Universities according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to note that the top three universities in this particular ranking have a ratio considerably higher than the other universities'. For the rest of the universities the value of the ratio decreases, but slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best universities in terms of ratio of international students according to QS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the ratio of international students\n",
    "qs_ranking_df[COLUMN_LABEL_INTERNATIONAL_RATIO] = qs_ranking_df[COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS] / qs_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS]\n",
    "\n",
    "# Clean up the computation taking care of unknown values (previously set at -1)\n",
    "qs_isratio_defined = (qs_ranking_df[COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS] != -1) | (qs_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS] != -1)\n",
    "qs_ranking_df.loc[~qs_isratio_defined, COLUMN_LABEL_INTERNATIONAL_RATIO] = float('nan')\n",
    "\n",
    "# Define a dataset for the result computation\n",
    "qs_international_students_rank_df = qs_ranking_df[[COLUMN_LABEL_COUNTRY, COLUMN_LABEL_REGION, COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS,\n",
    "                                                   COLUMN_LABEL_TOTAL_STUDENTS, COLUMN_LABEL_INTERNATIONAL_RATIO]]\n",
    "qs_international_students_rank_df = qs_international_students_rank_df.sort_values(COLUMN_LABEL_INTERNATIONAL_RATIO,\n",
    "                                                                                  ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the ratio, we plot it for the 20 universities with the highest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_international_students_rank_df[:20][COLUMN_LABEL_INTERNATIONAL_RATIO].plot(kind='barh', figsize=(10,7))\n",
    "\n",
    "plt.title('Top 20 Universities according to the ratio of international students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('International students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we can see from the plot that *London School of Economics and Political Science* has a very high ratio of international students, followed by EPFL. In this case, the universities in the second half of the ranking have a very similar ratio of international students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results from QS ranking aggregating by region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, we looked at the university with the best ratio in each region, for each of our defined ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_faculty_student_ratio_by_region_df = qs_faculty_students_rank_df.groupby(COLUMN_LABEL_REGION).head(1)\n",
    "qs_faculty_student_ratio_by_region_df[COLUMN_LABEL_FACULTY_RATIO].plot(kind='barh',figsize=(10,5),  color='green')\n",
    "\n",
    "plt.title('Top University per region according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for the international students' ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_international_students_ratio_by_region_df = qs_international_students_rank_df.groupby(COLUMN_LABEL_REGION).head(1)\n",
    "qs_international_students_ratio_by_region_df[COLUMN_LABEL_INTERNATIONAL_RATIO].plot(kind='barh', figsize=(10,5))\n",
    "\n",
    "plt.title('Top University per region according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results from QS ranking aggregating by country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, we plotted the universities with the highest values for each of the previously calculated ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First for the faculty to student ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_faculty_student_ratio_by_country_df = qs_faculty_students_rank_df.groupby(COLUMN_LABEL_COUNTRY).head(1)\n",
    "qs_faculty_student_ratio_by_country_df[COLUMN_LABEL_FACULTY_RATIO].plot(kind='barh', figsize=(10,10), color='green')\n",
    "\n",
    "plt.title('Top University per country according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then for the international students' ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_international_students_ratio_by_country_df = qs_international_students_rank_df.groupby(COLUMN_LABEL_COUNTRY).head(1)\n",
    "qs_international_students_ratio_by_country_df[COLUMN_LABEL_INTERNATIONAL_RATIO].plot(kind='barh', figsize=(10, 10))\n",
    "\n",
    "plt.title('Top University per country according to the ratio of international students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('International students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Scrape the Times ranking\n",
    "We now obtain the 200 top-ranking universities in [www.timeshighereducation.com](http://www.timeshighereducation.com) (ranking 2018), and repeat the analysis of the previous point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the auxiliary functions that we will need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_value_from_percentage(total, percentage):\n",
    "    \"\"\"Function that returns a value, calculated as a percentage of the given 'total'.\n",
    "    \n",
    "    total -- the value corresponding to 100%\n",
    "    percentage -- the desired percentage of the total\n",
    "    \n",
    "    return the calculated value\n",
    "    \"\"\"\n",
    "    \n",
    "    total = int(total)\n",
    "    percentage = float(percentage)\n",
    "    \n",
    "    return round((total/100) * percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_value_from_proportion(total, proportion):\n",
    "    \"\"\"Function to compute the proportion of a given total.\n",
    "    \n",
    "    total -- the value on which to calculate the percentage\n",
    "    proportion -- the proportion value\n",
    "    \n",
    "    return the calculated value\n",
    "    \"\"\"\n",
    "    \n",
    "    total = int(total)\n",
    "    proportion = float(proportion)\n",
    "    \n",
    "    return round(total / proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def scrape_times_ranking():\n",
    "    \"\"\"Obtain the ranking from the top 200 of Times in a dataframe.\n",
    "    \n",
    "    return the dataframe containing all the informations of Times ranking\n",
    "    \"\"\"\n",
    "\n",
    "    data = requests.get(TIMES_RANKING_JSON).json()\n",
    "    university_list = []\n",
    "\n",
    "    # Iterate through the first 200 universities in the ranking\n",
    "    for i, d in enumerate(data['data'][:200]):\n",
    "        \n",
    "        # Preliminary computations to extract data\n",
    "        intern_student = compute_value_from_percentage(clean_str_number(d['stats_number_students']), \n",
    "                                                       clean_str_number(d['stats_pc_intl_students'])\n",
    "                                                      )\n",
    "    \n",
    "        faculty_member_total = compute_value_from_proportion(clean_str_number(d['stats_number_students']), \n",
    "                                                             clean_str_number(d['stats_student_staff_ratio'])\n",
    "                                                            )\n",
    "        \n",
    "        # Determine region from the data of the QS ranking stored in the metadata\n",
    "        try:\n",
    "            region = COUNTRY_REGION_METADATA.get_value(d['location'], 'Region')\n",
    "        except KeyError:\n",
    "            region = 'NaN'\n",
    "    \n",
    "        # Store the parsed information into a dictionary\n",
    "        info = {COLUMN_LABEL_RANK: (i+1), \n",
    "                COLUMN_LABEL_UNIVERSITY_NAME: search_standard_name(d['name']), \n",
    "                COLUMN_LABEL_COUNTRY: d['location'],\n",
    "                COLUMN_LABEL_REGION: region,\n",
    "                COLUMN_LABEL_TOTAL_STUDENTS: int(clean_str_number(d['stats_number_students'])),\n",
    "                COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS: int(intern_student),\n",
    "                COLUMN_LABEL_TOTAL_FACULTY: int(faculty_member_total)\n",
    "               }\n",
    "    \n",
    "        university_list.append(info)\n",
    "   \n",
    "    times_ranking_df = pd.DataFrame.from_dict(university_list)\n",
    "    return times_ranking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the functions we need, we scrape the webpage and serialize the dataframe. If the serialized object already exists, we deserialize it and do not scrape the page again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    times_ranking_df = pd.read_pickle('serial/times_save.p')\n",
    "except (OSError, IOError) as e:\n",
    "    times_ranking_df = scrape_times_ranking()\n",
    "    times_ranking_df.to_pickle('serial/times_save.p')\n",
    "    \n",
    "times_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set a meaningful unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_ranking_df.set_index(COLUMN_LABEL_UNIVERSITY_NAME, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after extrapolating the region information from the first dataset, we might have some missing data. Those will be manually handled to completely fill in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_ranking_df[times_ranking_df[COLUMN_LABEL_REGION] == 'NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually fix the missing data\n",
    "times_ranking_df.set_value('University of Luxembourg', COLUMN_LABEL_REGION, 'Europe')\n",
    "times_ranking_df.set_value('Lomonosov Moscow State University', COLUMN_LABEL_REGION, 'Europe')\n",
    "\n",
    "# Verification\n",
    "times_ranking_df[times_ranking_df[COLUMN_LABEL_COUNTRY] == 'Luxembourg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best universities in terms of ratio between faculty members and students according to Times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the ratio between faculty member and students\n",
    "times_ranking_df[COLUMNLABELE_FACULTY_RATIO] = (times_ranking_df[COLUMN_LABEL_TOTAL_FACULTY] /\n",
    "                                          times_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS])\n",
    "\n",
    "# Clean up the computation, taking care of unknown values (previously set at -1)\n",
    "times_isratio_defined = ((times_ranking_df[COLUMN_LABEL_TOTAL_FACULTY] != -1) |\n",
    "                         (times_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS] != -1))\n",
    "times_ranking_df.loc[~times_isratio_defined, COLUMN_LABEL_FACULTY_RATIO] = float('nan')\n",
    "\n",
    "# Define a dataset for the result computation\n",
    "times_faculty_students_rank_df = times_ranking_df[[COLUMN_LABEL_COUNTRY, COLUMN_LABEL_REGION, COLUMN_LABEL_TOTAL_FACULTY,\n",
    "                                                   COLUMN_LABEL_TOTAL_STUDENTS, COLUMN_LABEL_FACULTY_RATIO]]\n",
    "times_faculty_students_rank_df = times_faculty_students_rank_df.sort_values(COLUMN_LABEL_FACULTY_RATIO,\n",
    "                                                                            ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the ratio, we plot it for the 20 universities with the highest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_faculty_students_rank_df[:20][COLUMN_LABEL_FACULTY_RATIO].plot(kind='barh', figsize=(10,7), color='green')\n",
    "\n",
    "plt.title('Top 20 Universities according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this ranking, there are two groups of universities with very similar values for their *faculty to students* ratio. This is different from the previous plot for the QS ranking, where the decrease in the ratio value was more gradual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which are the best universities in terms of ratio of international students according to Times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the ratio of international students\n",
    "times_ranking_df[COLUMN_LABEL_INTERNATIONAL_RATIO] = (times_ranking_df[COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS] /\n",
    "                                                times_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS])\n",
    "\n",
    "# Clean up the computation taking care of unknown values (previously set at -1)\n",
    "times_isratio_defined = ((times_ranking_df[COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS] != -1) |\n",
    "                         (times_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS] != -1))\n",
    "times_ranking_df.loc[~times_isratio_defined, COLUMN_LABEL_INTERNATIONAL_RATIO] = float('nan')\n",
    "\n",
    "# Define a dataset for the result computation\n",
    "times_international_students_rank_df = times_ranking_df[[COLUMN_LABEL_COUNTRY, COLUMN_LABEL_REGION, COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS,\n",
    "                                                         COLUMN_LABEL_TOTAL_STUDENTS, COLUMN_LABEL_INTERNATIONAL_RATIO]]\n",
    "times_international_students_rank_df = times_international_students_rank_df.sort_values(COLUMN_LABEL_INTERNATIONAL_RATIO,\n",
    "                                                                                        ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the ratio, we plot it for the 20 universities with the highest values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_international_students_rank_df[:20][COLUMN_LABEL_INTERNATIONAL_RATIO].plot(kind='barh', figsize=(10,7))\n",
    "\n",
    "plt.title('Top 20 Universities according to the ratio of international students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('International students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is very similar to the one for the QS ranking, regarding the fact that the universities in the second half of the ranking have a very similar ratio of international students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results from Times ranking aggregating by region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, we looked at the university with the best ratio in each region, for each of our defined ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the faculty to student ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_faculty_student_ratio_by_region_df = times_faculty_students_rank_df.groupby(COLUMN_LABEL_REGION).head(1)\n",
    "times_faculty_student_ratio_by_region_df[COLUMN_LABEL_FACULTY_RATIO].plot(kind='barh',figsize=(10,5),  color='green')\n",
    "\n",
    "plt.title('Top University per region according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the international to total student ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_international_students_ratio_by_region_df = times_international_students_rank_df.groupby(COLUMN_LABEL_REGION).head(1)\n",
    "times_international_students_ratio_by_region_df[COLUMN_LABEL_INTERNATIONAL_RATIO].plot(kind='barh', figsize=(10, 5))\n",
    "\n",
    "plt.title('Top University per region according to the ratio of international students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('International students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results from Times ranking aggregating by country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, we looked at the university with the best ratio in each country, for each of our defined ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the faculty members to total students ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_faculty_student_ratio_by_country_df = times_faculty_students_rank_df.groupby(COLUMN_LABEL_COUNTRY).head(1)\n",
    "times_faculty_student_ratio_by_country_df[COLUMN_LABEL_FACULTY_RATIO].plot(kind='barh', figsize=(10,10), color='green')\n",
    "\n",
    "plt.title('Top University per country according to ratio between faculty members and students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Faculty members - Total students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the international to total student ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_international_students_ratio_by_country_df = times_international_students_rank_df.groupby(COLUMN_LABEL_COUNTRY).head(1)\n",
    "times_international_students_ratio_by_country_df[COLUMN_LABEL_INTERNATIONAL_RATIO].plot(kind='barh', figsize=(10, 10))\n",
    "\n",
    "plt.title('Top University per country according to the ratio of international students')\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('International students ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# Task 3 - Merge the dataframes\n",
    "In this task we merge the two DataFrames created in tasks 1 and 2 using university names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging is trivial because we have already handled the standardization of University Names during the scraping task. As explained previously, we looked up the name in the WikiData database to obtain the WikiData formatted entry (it is carried out using the function `search_standard_name`).\n",
    "\n",
    "Therefore and since both rankings have names from the WikiData database, merging gives a perfect result. We first do some reorganization of the two dataframes as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create column containing university name on which do the merging\n",
    "qs_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME] = qs_ranking_df.index\n",
    "times_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME] = times_ranking_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the values in QS ranking for perfect merge\n",
    "qs_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME] = qs_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME].str.strip()\n",
    "qs_ranking_df[COLUMN_LABEL_COUNTRY] = qs_ranking_df[COLUMN_LABEL_COUNTRY].str.strip()\n",
    "\n",
    "# Clean up the values in Times ranking for perfect merge\n",
    "times_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME] = times_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME].str.strip()\n",
    "times_ranking_df[COLUMN_LABEL_COUNTRY] = times_ranking_df[COLUMN_LABEL_COUNTRY].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we merge the two dataframes into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge the dataframes via an outer join on the cols name, country and region\n",
    "merged_ranking_df = pd.merge(qs_ranking_df, times_ranking_df, \n",
    "                             on=[COLUMN_LABEL_UNIVERSITY_NAME, COLUMN_LABEL_REGION, COLUMN_LABEL_COUNTRY], \n",
    "                             how='outer', \n",
    "                             suffixes=('_QS', '_TM')\n",
    "                            )\n",
    "\n",
    "# Use the University Name as an index for the merged dataframe too\n",
    "merged_ranking_df.set_index(COLUMN_LABEL_UNIVERSITY_NAME, inplace=True)\n",
    "\n",
    "merged_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The universities that appear in both rankings have some information repeated twice. These repeated values are different in many cases, although very similar. For the universities that only appear in one of the rankings, many of the values are missing.\n",
    "\n",
    "We compute the mean for the repeated columns that contain information about the university - while still keeping track of the university position in each ranking. This also allows us to remove as many NaN values as possible, since the mean computation is ignoring the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace -1 values for None values\n",
    "merged_ranking_df.replace(-1, float('nan'), inplace=True)\n",
    "\n",
    "cols = [COLUMN_LABEL_TOTAL_STUDENTS, COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS, COLUMN_LABEL_TOTAL_FACULTY, \n",
    "        COLUMN_LABEL_FACULTY_RATIO, COLUMN_LABEL_INTERNATIONAL_RATIO]\n",
    "\n",
    "for x in cols:\n",
    "    merged_ranking_df[x] = merged_ranking_df[[x + '_QS', x + '_TM']].mean(axis=1)\n",
    "    merged_ranking_df.drop([x + '_QS', x + '_TM'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of the final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first look at the descriptive statistics for all the numeric variables in the merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ranking_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to see how the top universities are distributed among the continents. Nearly half of these top universities are in Europe, and around one fourth of them are in North America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explode = (0, 0, 0, 0.1, 0.2, 0.3)\n",
    "merged_ranking_df[COLUMN_LABEL_REGION].value_counts().plot(kind='pie', autopct='%1.1f%%', figsize=(10,10),fontsize=17, explode = explode)\n",
    "\n",
    "plt.ylabel(\"\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can classify the universities according to their size. We are considering that their size is determined by the number of students, with the same classification that was used for the QS ranking (Described [here](http://www.iu.qs.com/university-rankings/qs-classifications/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def university_sizes(x):\n",
    "    \"\"\"Returns a size label based on the number of students.\"\"\"\n",
    "    if not x:\n",
    "        return None\n",
    "    else:\n",
    "        return ('Small' if x < 5000 else 'Medium' if x < 12000\n",
    "                else 'Large' if x < 30000 else 'Extra Large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_ranking_df['Size'] = merged_ranking_df[COLUMN_LABEL_TOTAL_STUDENTS].apply(lambda x: university_sizes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the proportions of top universities according to their size, it is interesting to see that over 80% of them have more than 30,000 students - and out of these, 30% are considered to be extra large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode = (0, 0, 0.1, 0.2)\n",
    "merged_ranking_df['Size'].value_counts().plot(kind='pie', autopct='%1.1f%%', figsize=(10,10), fontsize=17, explode = explode)\n",
    "\n",
    "plt.ylabel(\"\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for a consistency on the computed ratios for universities in a certain region or of a certain size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following boxplots we want to identify outliers in the faculty per student ratio, and see if there is a difference in the ratio depending on the region and size of the university. \n",
    "\n",
    "We can observe that for the faculty to student ratio there are indeed differences depending on the regions. If we focus our interesting in the North American and the European universities (as shown previously, they account for nearly 75% of the dataset), we see that the medians are similar and below 0.10. However, for European universities the distribution of the ratio is more symmetrical.\n",
    "\n",
    "Regarding the size there are differences between the small and the extra large universities, whereas the distribution is similar for medium and large ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=COLUMN_LABEL_REGION, y=COLUMN_LABEL_FACULTY_RATIO, data=merged_ranking_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Size', y=COLUMN_LABEL_FACULTY_RATIO, data=merged_ranking_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to repeat the previous analysis for the international students ratio.\n",
    "\n",
    "In the case of the international students ratio, the universities in Latin America are some of the least international ones. The universities in Oceania appear to be the most international ones. In this case, the distribution of the ratio for North American Universities is more symmetrical than for European, although it has a similar median for both countries.\n",
    "\n",
    "Regarding the size, the median for the ratio is very similar for the four sizes of university. We can also observe that this ratio is more variable for small universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=COLUMN_LABEL_REGION, y=COLUMN_LABEL_INTERNATIONAL_RATIO, data=merged_ranking_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Size', y=COLUMN_LABEL_INTERNATIONAL_RATIO, data=merged_ranking_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for a consistency for students and faculty members when a university has a large international students ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we classify universities in three groups depending on their internationality ratio. We then plot the number of students and the ratio of faculty members for each of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_val = merged_ranking_df[COLUMN_LABEL_INTERNATIONAL_RATIO].max() / 3\n",
    "int_class = ['Low', 'Medium', 'High']\n",
    "merged_ranking_df['Internationality'] = merged_ranking_df[COLUMN_LABEL_INTERNATIONAL_RATIO].apply(\n",
    "    lambda x: int_class[0] if x < int_val else int_class[1] if x < int_val*2 else int_class[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplots we can observe that the most international universities seem to have a lower number of total students, i.e. they appear to be smaller in size.\n",
    "\n",
    "The faculty to students ratio has similar medians for the three groups of universities. We can also see that the number of outliers is the lowest for the *most international* universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=COLUMN_LABEL_TOTAL_STUDENTS, y='Internationality', data=merged_ranking_df, order=int_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=COLUMN_LABEL_FACULTY_RATIO, y='Internationality', data=merged_ranking_df, order=int_class);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO comment the above plots (I think it's all done except point 3)\n",
    "    1. Why these plots?\n",
    "    2. Which correlations we found?\n",
    "    3. What are we missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ranking_df.plot(x=COLUMN_LABEL_RANK + '_QS', y=COLUMN_LABEL_RANK+'_TM', kind='scatter', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ranking_df.plot(x=COLUMN_LABEL_RANK + '_QS', y=COLUMN_LABEL_TOTAL_FACULTY, kind='scatter', alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we obtain the correlation matrix for all the numeric variables. We then plot it for a better interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['{0}_QS'.format(COLUMN_LABEL_RANK), '{0}_TM'.format(COLUMN_LABEL_RANK), COLUMN_LABEL_REGION,\n",
    "        COLUMN_LABEL_TOTAL_STUDENTS, COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS, COLUMN_LABEL_TOTAL_FACULTY,\n",
    "        COLUMN_LABEL_FACULTY_RATIO, COLUMN_LABEL_INTERNATIONAL_RATIO]\n",
    "\n",
    "merged_ranking_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(merged_ranking_df[cols].corr())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Choose one from below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can see that there aren't any strong correlations, except for the two ranks, between the variables we are considering. Since there is no redundant information, we will use *all* of these variables for the ranking system we develop in task 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot we can see that the strongest correlations are found between the two ranks and between the number of total students and the number of faculty members. \n",
    "\n",
    "We consider that there is no redundant information, and we will use *all* of these variables for computing our ranking system in task 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Finding the best university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though at the end of task 4 we noticed there is a somewhat strong correlation between the two ranks, we don't have enough data to recreate their scoring criteria. Nevertheless, we have enough variables to create a new ranking system - and we can use the already calculated ranks as a small bias. \n",
    "\n",
    "In our view, a ranking based on arithmetic means between everything we know about the two ranks wouldn't give us a satisfactory result. This would give us a system with relatively high correlations with our previous one but that is not exactly what we want to achieve. Our rationale was that, even if a certain criteria allows for a really good differentiation between all the universities in the world, as a whole, it might not be the best criteria when addressing only a subset of these - namely the *elite*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing universities with NaN values \n",
    "If we can't properly score a university because of missing data, we remove it from the ranking altogether. Allowing those universities to be score based on the parameters they have left, seen that we already have little variables to rely on, would increase their ranks' volatility by a big margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs_ranking_df.dropna(inplace=True)\n",
    "times_ranking_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reseting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs_ranking_df.set_index(qs_ranking_df[COLUMN_LABEL_RANK], drop=True, inplace=True)\n",
    "times_ranking_df.set_index(times_ranking_df[COLUMN_LABEL_RANK], drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing unnecessary columns\n",
    "We decided to ignore country-specific biases. This means that, from this point on, 'Country' and 'Region' should have no impact in our final university ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_ranking_df.drop([COLUMN_LABEL_COUNTRY, COLUMN_LABEL_REGION], axis=1, inplace=True)\n",
    "times_ranking_df.drop([COLUMN_LABEL_COUNTRY, COLUMN_LABEL_REGION], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QS Ranking dataframe\n",
    "qs_rename_dic = {\n",
    "    'Rank': COLUMN_LABEL_RANK,\n",
    "    'Total student': COLUMN_LABEL_TOTAL_STUDENTS,\n",
    "    'University name': COLUMN_LABEL_UNIVERSITY_NAME,\n",
    "    'Total faculty member': COLUMN_LABEL_TOTAL_FACULTY,\n",
    "    'Faculty/students ratio': COLUMN_LABEL_FACULTY_RATIO,\n",
    "    'Intern/student ratio': COLUMN_LABEL_INTERNATIONAL_RATIO,\n",
    "    'International student': COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS,\n",
    "    'International faculty member': COLUMN_LABEL_TOTAL_INTERNATIONAL_FACULTY\n",
    "}\n",
    "qs_ranking_df.rename(columns=qs_rename_dic, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TM Ranking dataframe\n",
    "times_rename_dic = {\n",
    "    'Rank': COLUMN_LABEL_RANK,\n",
    "    'Total student': COLUMN_LABEL_TOTAL_STUDENTS,\n",
    "    'University name': COLUMN_LABEL_UNIVERSITY_NAME,\n",
    "    'Total faculty member': COLUMN_LABEL_TOTAL_FACULTY,\n",
    "    'Faculty/students ratio': COLUMN_LABEL_FACULTY_RATIO,\n",
    "    'Intern/student ratio': COLUMN_LABEL_INTERNATIONAL_RATIO,\n",
    "    'International student': COLUMN_LABEL_TOTAL_INTERNATIONAL_STUDENTS\n",
    "}\n",
    "times_ranking_df.rename(columns=times_rename_dic, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Calculating the relationship between each variable and 'Rank'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fully understand how we should go about creating a new ranking system, we first try to learn which *numerical* variables most strongly correlate to rank. Now, since the information we have is very little do do a proper evaluation on things like 'research' we will purposefully assume a certain bias: \"Whatever it is the top universities are doing that we don't know, they must be doing it right - since they are at the top of their ranking\".\n",
    "\n",
    "The above assumption translates into creating a weighted distribution for rank correlation (instead of simply analysing the sampled values). Each university will have an assigned weight that decreses linearly, in a way directly proportional to rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANK_MAX = 1\n",
    "RANK_MIN = 200\n",
    "\n",
    "def get_sample_weight(rank, rank_min, rank_max):\n",
    "    '''\n",
    "    Calculates the weight of a sample according to\n",
    "    its respective rank (and the rank's range).\n",
    "    '''\n",
    "    return (rank_min - (rank - rank_max))\n",
    "\n",
    "def get_weighted_mean(column):\n",
    "    '''\n",
    "    Calculates the weighted mean over a column's values.\n",
    "    The weights are calculated linearly, always decresing\n",
    "    proportionaly to the rank_offset (rank-1).\n",
    "    '''\n",
    "    weighted_sum = 0\n",
    "    hypothetical_samples = -1\n",
    "    \n",
    "    for rank_offset, sample in column.iteritems():\n",
    "        sample_weight = get_sample_weight(rank_offset+1, RANK_MIN, RANK_MAX)\n",
    "        weighted_sum += sample_weight * sample\n",
    "        hypothetical_samples += sample_weight\n",
    "    return weighted_sum / hypothetical_samples\n",
    "\n",
    "def get_weighted_std(column):\n",
    "    '''\n",
    "    Calculates the weighted santdard deviation over a \n",
    "    column's values.\n",
    "    '''\n",
    "    weighted_mean = get_weighted_mean(column)\n",
    "    weighted_sum = 0\n",
    "    hypothetical_samples = -1\n",
    "    \n",
    "    for rank_offset, sample in column.iteritems():\n",
    "        sample_weight = get_sample_weight(rank_offset+1, RANK_MIN, RANK_MAX)\n",
    "        weighted_sum += sample_weight * pow(sample_weight - weighted_mean, 2.0)\n",
    "        hypothetical_samples += sample_weight\n",
    "    return weighted_sum / hypothetical_samples\n",
    "\n",
    "def get_weighted_var(column):\n",
    "    '''\n",
    "    Calculates the weighted variance over a column's values.\n",
    "    '''\n",
    "    weighted_std = get_weighted_std(column)\n",
    "    return pow(weighted_std, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to compare the different distributions afterwards, we use a normalized version of the ranking dataframes to calculate the correlation dataframe. That dataframe simply divides all the values in each column by that column's maximum value, to make sure we have values between 0 and 1 - represented by **numeric_component_normalized_df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rank_correlation_df(dataframe):\n",
    "    '''\n",
    "    Creates a new dataframe with information about\n",
    "    each of the variables' distributions, according\n",
    "    to rank.\n",
    "    '''\n",
    "    ranking_correlation_df = pd.DataFrame()\n",
    "    numeric_component_normalized_df = dataframe.drop([COLUMN_LABEL_UNIVERSITY_NAME, COLUMN_LABEL_RANK], axis=1).apply(lambda x: x / x.max())\n",
    "    ranking_correlation_df['Mean'] = numeric_component_normalized_df.apply(lambda x: x.mean())\n",
    "    ranking_correlation_df['Weighted Mean'] = numeric_component_normalized_df.apply(lambda x: get_weighted_mean(x))\n",
    "    ranking_correlation_df['Stddev'] = numeric_component_normalized_df.apply(lambda x: x.std())\n",
    "    ranking_correlation_df['Weighted Stddev'] = numeric_component_normalized_df.apply(lambda x: get_weighted_std(x))\n",
    "    ranking_correlation_df['Variance'] = numeric_component_normalized_df.apply(lambda x: x.var())\n",
    "    ranking_correlation_df['Weighted Variance'] = numeric_component_normalized_df.apply(lambda x: get_weighted_var(x))\n",
    "    return ranking_correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ranking-specific correlation dataframes\n",
    "qs_rank_correlation_df = get_rank_correlation_df(qs_ranking_df)\n",
    "times_rank_correlation_df = get_rank_correlation_df(times_ranking_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_rank_correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rank_correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Calculating each variable's score contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the distributions we found to infer the ideal contribution of each parameter to the final evaluation. The criteria is simple:\n",
    "\n",
    "    1. Pick a 'penalization' column\n",
    "    2. Do a sum over that column's values\n",
    "    3. Iterate over each criterion (row)\n",
    "    4. Get their value for the 'penalization' column\n",
    "    5. Assign a contribution (%) to that criterion\n",
    "    6. Store the calculated contribution in a new column\n",
    "    \n",
    "Firstly, the contribution assigned to each criterion, in step 5, is *equal* to the percentage of the sum (step 2) represented by the criterion's value (step 4).\n",
    "\n",
    "Secondly, as our 'penalization' column we can use either *Stddev* or *Variance* (or their weighted counterparts) and then power all their values to *-1*. This means that the higher the *Stddev* (or *Variance*) the smaller the final contribution of that parameter. This inherently makes it such that variables with a lower correlation to rank (hence higher values for *Stddev* and *Variance*) should have less impact on the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score_contribution_as_percentage(column):\n",
    "    '''\n",
    "    Calculates a percentage-wise score contribution, \n",
    "    linearly, according to a column's values.\n",
    "    '''\n",
    "    criteria_sum = column.sum()\n",
    "    contribution_dict = {}\n",
    "    \n",
    "    for criterion, criterion_value in column.iteritems():\n",
    "        contribution_dict[criterion] = 100 * (criterion_value / criteria_sum)\n",
    "    return contribution_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate contribution maps for QS and TM rankings\n",
    "qs_contribution_percentage_map = get_score_contribution_as_percentage(qs_rank_correlation_df['Variance'].apply(lambda x: 1/x))\n",
    "times_contribution_percentage_map = get_score_contribution_as_percentage(times_rank_correlation_df['Variance'].apply(lambda x: 1/x))\n",
    "\n",
    "# Assign the contribution percentages to the correlation dataframes\n",
    "qs_rank_correlation_df['Contribution Percent'] = pd.Series(qs_contribution_percentage_map)\n",
    "times_rank_correlation_df['Contribution Percent'] = pd.Series(times_contribution_percentage_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_rank_correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rank_correlation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 - Calculate criterion-specific score for each university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we estimate the criterion-specific contributions, we then need to find a way to calculate a university's score for that same criterion. Again, we need to pick a 'penalization' function. \n",
    "\n",
    "The way we do it is assuming a *Gaussian* distribution around the *weighted mean* (and with a certain standard deviation). By finding **gaussian(x, mean, std)**, being *x* the university's value for a certain criterion, we get an overall score between 0 and 1 - being the highest score closer to the *weighted mean*.\n",
    "\n",
    "As a last step, we multiply this criterion-specific *score* by the criterion-specific *contribution* to get the final score's percentage - for a given university, for a given criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian(x, mean, std):\n",
    "    '''\n",
    "    Returns the value for a gaussian function\n",
    "    with mean 'mean' and standard deviation 'std',\n",
    "    at coordinate 'x'.\n",
    "    '''\n",
    "    return np.exp(-pow(x - mean, 2.0) / (2 * pow(std, 2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_criterion_specific_score(column, correlation_df):\n",
    "    '''\n",
    "    Returns a dictionary with a university's name as \n",
    "    keys and the column criterion's score as values.\n",
    "    '''\n",
    "    criterion_contribution = correlation_df['Contribution Percent'].get(column.name)\n",
    "    criterion_mean = correlation_df['Weighted Mean'].get(column.name)\n",
    "    criterion_std = correlation_df['Stddev'].get(column.name)\n",
    "\n",
    "    normalized_column = column / column.max()\n",
    "    university_score_dict = {}\n",
    "    \n",
    "    for university_name, criterion_x in normalized_column.iteritems():\n",
    "        criterion_value = gaussian(criterion_x, criterion_mean, criterion_std)\n",
    "        university_score_dict[university_name] = criterion_value * criterion_contribution\n",
    "        \n",
    "    return university_score_dict\n",
    "\n",
    "# Setting index to 'University Name' for both dataframes\n",
    "qs_ranking_df.set_index(qs_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME], drop=True, inplace=True)\n",
    "times_ranking_df.set_index(times_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME], drop=True, inplace=True)\n",
    "\n",
    "# Removing unnecessary columns\n",
    "qs_ranking_df.drop([COLUMN_LABEL_UNIVERSITY_NAME, COLUMN_LABEL_RANK], axis=1, inplace=True)\n",
    "times_ranking_df.drop([COLUMN_LABEL_UNIVERSITY_NAME, COLUMN_LABEL_RANK], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpack_score_info_to_df(column):\n",
    "    '''\n",
    "    Creates a new dataframe that, for every\n",
    "    criterion, unpacks a score dict's values\n",
    "    into rows.\n",
    "    '''\n",
    "    score_df = pd.DataFrame()\n",
    "    \n",
    "    for criterion, university_score_map in column.iteritems():\n",
    "        score_df[criterion] = pd.Series(university_score_map)\n",
    "    \n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the calculated scores are then stored in a separate dataframe, for clarity and simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating new dataframes to store score info\n",
    "qs_score_df = unpack_score_info_to_df(qs_ranking_df.apply(lambda x: get_criterion_specific_score(x, qs_rank_correlation_df)))\n",
    "times_score_df = unpack_score_info_to_df(times_ranking_df.apply(lambda x: get_criterion_specific_score(x, times_rank_correlation_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 - Calculate overall score for each university"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe with all the universities' scores for the criteria we used, we simply need to add all those values and store the result as a new column, *Total*.\n",
    "\n",
    "To get our final ranking, we just need a few more steps:\n",
    "\n",
    "    1. Add a 'Total' column to both **qs_score_df** and **times_score_df**\n",
    "    2. Add a 'University Name' column to the same dataframes (taken from index)\n",
    "    3. Do an outer merge on the necessary columns, based on 'University Name'\n",
    "    4. Calculate the average score between our QS and TM methodologies\n",
    "    5. Sort the dataframe according to the averaged score\n",
    "    6. Re-index the dataframe (so that the index now represents the rank)\n",
    "\n",
    "As stated before if, for whatever reason, a university does not exist in both rankings only one of the scores will be used as its full score (instead of the average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a 'Total' column with a university's overall score\n",
    "qs_score_df['Total'] = qs_score_df.apply(lambda x: x.sum(), axis=1)\n",
    "times_score_df['Total'] = times_score_df.apply(lambda x: x.sum(), axis=1)\n",
    "\n",
    "# Add university name as column\n",
    "qs_score_df[COLUMN_LABEL_UNIVERSITY_NAME] = qs_score_df.index\n",
    "times_score_df[COLUMN_LABEL_UNIVERSITY_NAME] = times_score_df.index\n",
    "\n",
    "# Create merged dataframe for overall ranking\n",
    "new_ranking_df = qs_score_df[['Total', COLUMN_LABEL_UNIVERSITY_NAME]].merge(times_score_df[['Total', COLUMN_LABEL_UNIVERSITY_NAME]], left_on=COLUMN_LABEL_UNIVERSITY_NAME, right_on=COLUMN_LABEL_UNIVERSITY_NAME, how='outer')\n",
    "new_ranking_df.set_index([COLUMN_LABEL_UNIVERSITY_NAME], drop=True, inplace=True)\n",
    "new_ranking_df.rename(columns={'Total_x':'QS Score', 'Total_y':'TM Score'}, inplace=True)\n",
    "\n",
    "# Add new column with final averaged score\n",
    "new_ranking_df['Final Score'] = new_ranking_df.apply(lambda x: x.sum() / (x.size - x.isnull().sum()), axis=1)\n",
    "\n",
    "# Sort dataframe according to final score\n",
    "new_ranking_df = new_ranking_df.sort_values(['Final Score'], ascending=False)\n",
    "\n",
    "# Add university name as a column and create new ranking as index\n",
    "new_ranking_df[COLUMN_LABEL_UNIVERSITY_NAME] = new_ranking_df.index\n",
    "new_ranking_df.index = np.arange(1, len(new_ranking_df)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 - Conclusion\n",
    "Now we just have to take name of the university at the first index to learn which one is the best according to our ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranking_df.get_value(1, COLUMN_LABEL_UNIVERSITY_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
