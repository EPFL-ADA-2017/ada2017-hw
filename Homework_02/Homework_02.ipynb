{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will extract interesting information from www.topuniversities.com and www.timeshighereducation.com, two platforms that maintain a global ranking of worldwide universities. This ranking is not offered as a downloadable dataset, so you will have to find a way to scrape the information we need! You are not allowed to download manually the entire ranking -- rather you have to understand how the server loads it in your browser. For this task, Postman with the Interceptor extension can help you greatly. We recommend that you watch this brief tutorial to understand quickly how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constans definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QS_RANKING_URL = 'https://www.topuniversities.com/university-rankings/world-university-rankings/2018'\n",
    "QS_RANKING_JSON = 'https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508104120137'\n",
    "\n",
    "TIMES_RANKING_URL = 'http://timeshighereducation.com/world-university-rankings/2018/world-ranking'\n",
    "TIMES_RANKING_JSON = 'https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General use functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_html_parser(url):\n",
    "    '''\n",
    "    Function to build a parser object of type BeautifulSoup\n",
    "    \n",
    "    url      the webpage url to which send a get request to\n",
    "    \n",
    "    return   a parser of the given webpage\n",
    "    '''\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    page_body = r.text\n",
    "    \n",
    "    soup = BeautifulSoup(page_body, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Obtain the 200 top-ranking universities in www.topuniversities.com (ranking 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_detail_page(url_detail):\n",
    "    '''\n",
    "    Function that parses the missing informations from the detail page of the university from the QS website\n",
    "    \n",
    "    Return   a dictionary with all the data found as integers values\n",
    "    '''\n",
    "    \n",
    "    # Build a parser for the detail page\n",
    "    soup = build_html_parser(url_detail)\n",
    "    \n",
    "    # Obtain and clean up the total faculty member value\n",
    "    try:\n",
    "        faculty_member_total = soup.find('div', class_='total faculty').find('div', class_='number').text\n",
    "        faculty_member_total = faculty_member_total.strip('\\n').replace(',','')\n",
    "    except:\n",
    "        faculty_member_total = -1\n",
    "    \n",
    "    \n",
    "    # Obtain and clean up the international faculty member value\n",
    "    try:\n",
    "        faculty_member_inter = soup.find('div', class_='inter faculty').find('div', class_='number').text.strip('\\n')\n",
    "        faculty_member_inter = faculty_member_inter.strip('\\n').replace(',','')\n",
    "    except:\n",
    "        faculty_member_inter = -1\n",
    "    \n",
    "    # Obtain and clean up the total students value\n",
    "    try:\n",
    "        student_total = soup.find('div', class_='total student').find('div', class_='number').text.strip('\\n')\n",
    "        student_total = student_total.strip('\\n').replace(',','')\n",
    "    except:\n",
    "        student_total = -1\n",
    "    \n",
    "    # Obtain and clean up the international students value\n",
    "    try:\n",
    "        student_inter = soup.find('div', class_='total inter').find('div', class_='number').text.strip('\\n')\n",
    "        student_inter = student_inter.strip('\\n').replace(',','')\n",
    "    except:\n",
    "        student_inter = -1\n",
    "    \n",
    "    # Build a dictionary for the parsed informations\n",
    "    detail_info = {'Total faculty member' : int(faculty_member_total), \n",
    "                   'International faculty member' : int(faculty_member_inter), \n",
    "                   'Total student' : int(student_total), \n",
    "                   'International student' : int(student_inter)\n",
    "                  }\n",
    "    \n",
    "    return detail_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some work on the Postman Inspector, we found out that the GET Request made to the QS website ended up with multiple attached files to go with the response. One of those files was a JSON with all the infos from the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(QS_RANKING_JSON)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such data is stored as a list of dictionaries, as visible in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First cell:')\n",
    "print(data['data'][0], end='\\n\\n')\n",
    "\n",
    "print('Second cell:')\n",
    "print(data['data'][1], end='\\n\\n')\n",
    "\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_list = []\n",
    "\n",
    "# Iterate throu the first 200 elments of the list\n",
    "for d in data['data'][:200]:\n",
    "    \n",
    "    # Store the parsed information into a dictionary\n",
    "    info = {'Rank': d['rank_display'], \n",
    "            'University name': d['title'], \n",
    "            'Country': d['country'],\n",
    "            'Region' : d['region']\n",
    "           }\n",
    "    \n",
    "    # Extend the dictionary with the informations in the detail page\n",
    "    url_detail = 'https://www.topuniversities.com' +  d['url']\n",
    "    info.update( parse_detail_page( url_detail))\n",
    "    \n",
    "    university_list.append(info)\n",
    "    \n",
    "    \n",
    "qs_ranking_df = pd.DataFrame.from_dict(university_list)\n",
    "qs_ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_ranking_df.set_index(['University name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the two required ratios with the help of two auxiliary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_facutly_member_ratio(df):\n",
    "    '''\n",
    "    Co\n",
    "    '''\n",
    "    li = list()\n",
    "    for i, row in df.iterrows():\n",
    "        li.append(row['Total faculty member'] / row['Total student'])\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_student_ratio(df):\n",
    "    li = list()\n",
    "    for i, row in df.iterrows():\n",
    "        li.append(row['International student'] / row['Total student'])\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation results are stored in two new colums of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_ranking_df['Faculty/students ratio'] = compute_facutly_member_ratio( qs_ranking_df )\n",
    "qs_ranking_df['Intern/student ratio'] = compute_student_ratio( qs_ranking_df )\n",
    "\n",
    "qs_ranking_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the dataframe for the ratios computed (double click on the plot for zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = qs_ranking_df[['Faculty/students ratio', 'Intern/student ratio']].plot.bar( figsize=(150, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Scrape the Times ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(TIMES_RANKING_JSON)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_list = []\n",
    "\n",
    "# Iterate throu the first 200 elments of the list\n",
    "for d in data['data'][:200]:\n",
    "    \n",
    "    # Store the parsed information into a dictionary\n",
    "    info = {'Rank': d['rank'], \n",
    "            'University name': d['name'], \n",
    "            'Country': d['location']\n",
    "           }\n",
    "    \n",
    "    university_list.append(info)\n",
    "    \n",
    "    \n",
    "times_ranking_df = pd.DataFrame.from_dict(university_list)\n",
    "times_ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
